{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a85bed4f",
   "metadata": {},
   "source": [
    "## Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d2d76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install azure-ai-voicelive pyaudio python-dotenv azure-identity --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bac0b93",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b42cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import os\n",
    "import sys\n",
    "import asyncio\n",
    "import json\n",
    "import base64\n",
    "from datetime import datetime, timezone\n",
    "import logging\n",
    "import queue\n",
    "from typing import Union, Optional, Dict, Any, Mapping, Callable, TYPE_CHECKING, cast\n",
    "\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.core.credentials_async import AsyncTokenCredential\n",
    "from azure.identity.aio import AzureCliCredential, DefaultAzureCredential\n",
    "\n",
    "from azure.ai.voicelive.aio import connect\n",
    "from azure.ai.voicelive.models import (\n",
    "    AudioEchoCancellation,\n",
    "    AudioNoiseReduction,\n",
    "    AzureStandardVoice,\n",
    "    InputAudioFormat,\n",
    "    ItemType,\n",
    "    Modality,\n",
    "    OutputAudioFormat,\n",
    "    RequestSession,\n",
    "    ServerEventType,\n",
    "    ServerVad,\n",
    "    FunctionTool,\n",
    "    FunctionCallOutputItem,\n",
    "    ToolChoiceLiteral,\n",
    "    AudioInputTranscriptionOptions,\n",
    "    Tool,\n",
    ")\n",
    "from dotenv import load_dotenv\n",
    "import pyaudio\n",
    "\n",
    "if TYPE_CHECKING:\n",
    "    from azure.ai.voicelive.aio import VoiceLiveConnection\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f7d610",
   "metadata": {},
   "source": [
    "## Load Environment Variables\n",
    "\n",
    "Create a `.env` file in the same directory with the following variables:\n",
    "```\n",
    "AZURE_VOICELIVE_ENDPOINT=https://your-resource-name.services.ai.azure.com/\n",
    "AZURE_VOICELIVE_API_KEY=your-api-key\n",
    "AZURE_VOICELIVE_MODEL=gpt-realtime\n",
    "AZURE_VOICELIVE_VOICE=en-US-Ava:DragonHDLatestNeural\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd919cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "load_dotenv('./.env', override=True)\n",
    "\n",
    "# Configuration\n",
    "ENDPOINT = os.environ.get(\"AZURE_VOICELIVE_ENDPOINT\", \"https://your-resource-name.services.ai.azure.com/\")\n",
    "API_KEY = os.environ.get(\"AZURE_VOICELIVE_API_KEY\", \"\")\n",
    "MODEL = os.environ.get(\"AZURE_VOICELIVE_MODEL\", \"gpt-realtime\")\n",
    "VOICE = os.environ.get(\"AZURE_VOICELIVE_VOICE\", \"en-US-Ava:DragonHDLatestNeural\")\n",
    "USE_TOKEN_CREDENTIAL = False  # Set to True to use Azure CLI credential instead of API key\n",
    "\n",
    "INSTRUCTIONS = \"\"\"\n",
    "You are a helpful AI assistant with access to functions.\n",
    "Use the functions when appropriate to provide accurate, real-time information.\n",
    "If you are asked about the weather, please call the get_current_weather function.\n",
    "If you are asked about the time, please call the get_current_time function.\n",
    "Explain when you're using a function and include the results in your response naturally.\n",
    "Always start the conversation in English.\n",
    "\"\"\"\n",
    "\n",
    "print(f\"Endpoint: {ENDPOINT}\")\n",
    "print(f\"Model: {MODEL}\")\n",
    "print(f\"Voice: {VOICE}\")\n",
    "print(f\"Use Token Credential: {USE_TOKEN_CREDENTIAL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a44d25",
   "metadata": {},
   "source": [
    "## Set Up Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d2ba92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging\n",
    "if not os.path.exists('logs'):\n",
    "    os.makedirs('logs')\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "logfilename = f'logs/{timestamp}_voicelive_function_calling.log'\n",
    "\n",
    "logging.basicConfig(\n",
    "    filename=logfilename,\n",
    "    filemode=\"w\",\n",
    "    format='%(asctime)s:%(name)s:%(levelname)s:%(message)s',\n",
    "    level=logging.INFO\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(f\"Logging to: {logfilename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3efcc4f",
   "metadata": {},
   "source": [
    "## Import AudioProcessor\n",
    "\n",
    "Import the reusable AudioProcessor class from `audio_processor.py` which handles real-time audio capture and playback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7124b897",
   "metadata": {},
   "outputs": [],
   "source": [
    "from audio_processor import AudioProcessor\n",
    "\n",
    "print(\"AudioProcessor imported from audio_processor.py!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2692ad",
   "metadata": {},
   "source": [
    "## Define Function Tools\n",
    "\n",
    "These are the backend functions that can be called by the Voice Live assistant:\n",
    "- `get_current_time`: Returns the current time\n",
    "- `get_current_weather`: Returns simulated weather data for a location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c9d12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_current_time(arguments: Optional[Union[str, Mapping[str, Any]]] = None) -> Dict[str, Any]:\n",
    "    \"\"\"Get the current time.\"\"\"\n",
    "    if isinstance(arguments, str):\n",
    "        try:\n",
    "            args = json.loads(arguments)\n",
    "        except json.JSONDecodeError:\n",
    "            args = {}\n",
    "    else:\n",
    "        args = arguments if isinstance(arguments, dict) else {}\n",
    "\n",
    "    timezone_arg = args.get(\"timezone\", \"local\")\n",
    "    now = datetime.now()\n",
    "\n",
    "    if timezone_arg.lower() == \"utc\":\n",
    "        now = datetime.now(timezone.utc)\n",
    "        timezone_name = \"UTC\"\n",
    "    else:\n",
    "        timezone_name = \"local\"\n",
    "\n",
    "    formatted_time = now.strftime(\"%I:%M:%S %p\")\n",
    "    formatted_date = now.strftime(\"%A, %B %d, %Y\")\n",
    "\n",
    "    return {\"time\": formatted_time, \"date\": formatted_date, \"timezone\": timezone_name}\n",
    "\n",
    "\n",
    "def get_current_weather(arguments: Union[str, Mapping[str, Any]]) -> Dict[str, Any]:\n",
    "    \"\"\"Get the current weather for a location.\"\"\"\n",
    "    if isinstance(arguments, str):\n",
    "        try:\n",
    "            args = json.loads(arguments)\n",
    "        except json.JSONDecodeError:\n",
    "            logger.error(f\"Failed to parse weather arguments: {arguments}\")\n",
    "            return {\"error\": \"Invalid arguments\"}\n",
    "    else:\n",
    "        args = arguments if isinstance(arguments, dict) else {}\n",
    "\n",
    "    location = args.get(\"location\", \"Unknown\")\n",
    "    unit = args.get(\"unit\", \"celsius\")\n",
    "\n",
    "    # Simulated weather response\n",
    "    try:\n",
    "        return {\n",
    "            \"location\": location,\n",
    "            \"temperature\": 22 if unit == \"celsius\" else 72,\n",
    "            \"unit\": unit,\n",
    "            \"condition\": \"Partly Cloudy\",\n",
    "            \"humidity\": 65,\n",
    "            \"wind_speed\": 10,\n",
    "        }\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error getting weather: {e}\")\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "\n",
    "# Map of available functions\n",
    "AVAILABLE_FUNCTIONS: Dict[str, Callable] = {\n",
    "    \"get_current_time\": get_current_time,\n",
    "    \"get_current_weather\": get_current_weather,\n",
    "}\n",
    "\n",
    "# Test the functions\n",
    "print(\"Testing get_current_time:\")\n",
    "print(get_current_time())\n",
    "print(\"\\nTesting get_current_weather:\")\n",
    "print(get_current_weather({\"location\": \"Seattle, WA\", \"unit\": \"fahrenheit\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb164b2",
   "metadata": {},
   "source": [
    "## Define FunctionTool Schemas\n",
    "\n",
    "Create FunctionTool definitions with names, parameter schemas, and text descriptions for the Voice Live session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1daeffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function tools for Voice Live session\n",
    "FUNCTION_TOOLS: list[Tool] = [\n",
    "    FunctionTool(\n",
    "        name=\"get_current_time\",\n",
    "        description=\"Get the current time\",\n",
    "        parameters={\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"timezone\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The timezone to get the current time for, e.g., 'UTC', 'local'\",\n",
    "                }\n",
    "            },\n",
    "            \"required\": [],\n",
    "        },\n",
    "    ),\n",
    "    FunctionTool(\n",
    "        name=\"get_current_weather\",\n",
    "        description=\"Get the current weather in a given location\",\n",
    "        parameters={\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"location\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The city and state, e.g., 'San Francisco, CA'\",\n",
    "                },\n",
    "                \"unit\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"enum\": [\"celsius\", \"fahrenheit\"],\n",
    "                    \"description\": \"The unit of temperature to use (celsius or fahrenheit)\",\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"location\"],\n",
    "        },\n",
    "    ),\n",
    "]\n",
    "\n",
    "print(f\"Defined {len(FUNCTION_TOOLS)} function tools:\")\n",
    "for tool in FUNCTION_TOOLS:\n",
    "    print(f\"  - {tool.name}: {tool.description}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388d231c",
   "metadata": {},
   "source": [
    "## Define AsyncFunctionCallingClient Class\n",
    "\n",
    "This class handles:\n",
    "- Session setup with function tools\n",
    "- Event processing from Voice Live\n",
    "- Function call execution and response handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d998b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AsyncFunctionCallingClient:\n",
    "    \"\"\"Voice assistant with function calling capabilities using VoiceLive SDK patterns.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        endpoint: str,\n",
    "        credential: Union[AzureKeyCredential, AsyncTokenCredential],\n",
    "        model: str,\n",
    "        voice: str,\n",
    "        instructions: str,\n",
    "    ):\n",
    "        self.endpoint = endpoint\n",
    "        self.credential = credential\n",
    "        self.model = model\n",
    "        self.voice = voice\n",
    "        self.instructions = instructions\n",
    "        self.connection: Optional[\"VoiceLiveConnection\"] = None\n",
    "        self.audio_processor: Optional[AudioProcessor] = None\n",
    "        self.session_ready = False\n",
    "        self.conversation_started = False\n",
    "        self._active_response = False\n",
    "        self._response_api_done = False\n",
    "        self._pending_function_call: Optional[Dict[str, Any]] = None\n",
    "\n",
    "    async def start(self):\n",
    "        \"\"\"Start the voice assistant session.\"\"\"\n",
    "        try:\n",
    "            logger.info(\"Connecting to VoiceLive API with model %s\", self.model)\n",
    "\n",
    "            # Connect to VoiceLive WebSocket API\n",
    "            async with connect(\n",
    "                endpoint=self.endpoint,\n",
    "                credential=self.credential,\n",
    "                model=self.model,\n",
    "            ) as connection:\n",
    "                conn = connection\n",
    "                self.connection = conn\n",
    "\n",
    "                # Initialize audio processor\n",
    "                ap = AudioProcessor(conn)\n",
    "                self.audio_processor = ap\n",
    "\n",
    "                # Configure session for voice conversation\n",
    "                await self._setup_session()\n",
    "\n",
    "                # Start audio systems\n",
    "                ap.start_playback()\n",
    "\n",
    "                logger.info(\"Voice assistant with function calling ready!\")\n",
    "                print(\"\\n\" + \"=\" * 60)\n",
    "                print(\"üé§ VOICE ASSISTANT WITH FUNCTION CALLING READY\")\n",
    "                print(\"Try saying:\")\n",
    "                print(\"  ‚Ä¢ 'What's the current time?'\")\n",
    "                print(\"  ‚Ä¢ 'What's the weather in Seattle?'\")\n",
    "                print(\"Press Ctrl+C to exit\")\n",
    "                print(\"=\" * 60 + \"\\n\")\n",
    "\n",
    "                # Process events\n",
    "                await self._process_events()\n",
    "        except asyncio.CancelledError:\n",
    "            logger.info(\"Session cancelled by user\")\n",
    "            raise\n",
    "        finally:\n",
    "            if self.audio_processor:\n",
    "                self.audio_processor.shutdown()\n",
    "\n",
    "    async def _setup_session(self):\n",
    "        \"\"\"Configure the VoiceLive session for audio conversation with function tools.\"\"\"\n",
    "        logger.info(\"Setting up voice conversation session with function tools...\")\n",
    "\n",
    "        # Create voice configuration\n",
    "        voice_config: Union[AzureStandardVoice, str]\n",
    "        if self.voice.startswith(\"en-US-\") or self.voice.startswith(\"en-CA-\") or \"-\" in self.voice:\n",
    "            # Azure voice\n",
    "            voice_config = AzureStandardVoice(name=self.voice)\n",
    "        else:\n",
    "            # OpenAI voice (alloy, echo, fable, onyx, nova, shimmer)\n",
    "            voice_config = self.voice\n",
    "\n",
    "        # Create turn detection configuration\n",
    "        turn_detection_config = ServerVad(\n",
    "            threshold=0.5,\n",
    "            prefix_padding_ms=300,\n",
    "            silence_duration_ms=500)\n",
    "\n",
    "        # Create session configuration with function tools\n",
    "        session_config = RequestSession(\n",
    "            modalities=[Modality.TEXT, Modality.AUDIO],\n",
    "            instructions=self.instructions,\n",
    "            voice=voice_config,\n",
    "            input_audio_format=InputAudioFormat.PCM16,\n",
    "            output_audio_format=OutputAudioFormat.PCM16,\n",
    "            turn_detection=turn_detection_config,\n",
    "            input_audio_echo_cancellation=AudioEchoCancellation(),\n",
    "            input_audio_noise_reduction=AudioNoiseReduction(type=\"azure_deep_noise_suppression\"),\n",
    "            tools=FUNCTION_TOOLS,\n",
    "            tool_choice=ToolChoiceLiteral.AUTO,\n",
    "            input_audio_transcription=AudioInputTranscriptionOptions(model=\"whisper-1\"),\n",
    "        )\n",
    "\n",
    "        conn = self.connection\n",
    "        assert conn is not None, \"Connection must be established before setting up session\"\n",
    "        await conn.session.update(session=session_config)\n",
    "\n",
    "        logger.info(\"Session configuration with function tools sent\")\n",
    "\n",
    "    async def _process_events(self):\n",
    "        \"\"\"Process events from the VoiceLive connection.\"\"\"\n",
    "        try:\n",
    "            conn = self.connection\n",
    "            assert conn is not None, \"Connection must be established before processing events\"\n",
    "            async for event in conn:\n",
    "                await self._handle_event(event)\n",
    "        except asyncio.CancelledError:\n",
    "            logger.info(\"Event processing cancelled\")\n",
    "            raise\n",
    "        except Exception:\n",
    "            logger.exception(\"Error processing events\")\n",
    "            raise\n",
    "\n",
    "    async def _handle_event(self, event):\n",
    "        \"\"\"Handle different types of events from VoiceLive.\"\"\"\n",
    "        logger.debug(\"Received event: %s\", event.type)\n",
    "        ap = self.audio_processor\n",
    "        conn = self.connection\n",
    "        assert ap is not None, \"AudioProcessor must be initialized\"\n",
    "        assert conn is not None, \"Connection must be established\"\n",
    "\n",
    "        if event.type == ServerEventType.SESSION_UPDATED:\n",
    "            logger.info(\"Session ready: %s\", event.session.id)\n",
    "            self.session_ready = True\n",
    "\n",
    "            # Proactive greeting\n",
    "            if not self.conversation_started:\n",
    "                self.conversation_started = True\n",
    "                logger.info(\"Sending proactive greeting request\")\n",
    "                try:\n",
    "                    await conn.response.create()\n",
    "                except Exception:\n",
    "                    logger.exception(\"Failed to send proactive greeting request\")\n",
    "\n",
    "            # Start audio capture once session is ready\n",
    "            ap.start_capture()\n",
    "\n",
    "        elif event.type == ServerEventType.INPUT_AUDIO_BUFFER_SPEECH_STARTED:\n",
    "            logger.info(\"User started speaking - stopping playback\")\n",
    "            print(\"üé§ Listening...\")\n",
    "\n",
    "            ap.skip_pending_audio()\n",
    "\n",
    "            # Only cancel if response is active and not already done\n",
    "            if self._active_response and not self._response_api_done:\n",
    "                try:\n",
    "                    await conn.response.cancel()\n",
    "                    logger.debug(\"Cancelled in-progress response due to barge-in\")\n",
    "                except Exception as e:\n",
    "                    if \"no active response\" in str(e).lower():\n",
    "                        logger.debug(\"Cancel ignored - response already completed\")\n",
    "                    else:\n",
    "                        logger.warning(\"Cancel failed: %s\", e)\n",
    "\n",
    "        elif event.type == ServerEventType.INPUT_AUDIO_BUFFER_SPEECH_STOPPED:\n",
    "            logger.info(\"üé§ User stopped speaking\")\n",
    "            print(\"ü§î Processing...\")\n",
    "\n",
    "        elif event.type == ServerEventType.RESPONSE_CREATED:\n",
    "            logger.info(\"ü§ñ Assistant response created\")\n",
    "            self._active_response = True\n",
    "            self._response_api_done = False\n",
    "\n",
    "        elif event.type == ServerEventType.RESPONSE_AUDIO_DELTA:\n",
    "            logger.debug(\"Received audio delta\")\n",
    "            ap.queue_audio(event.delta)\n",
    "\n",
    "        elif event.type == ServerEventType.RESPONSE_AUDIO_DONE:\n",
    "            logger.info(\"ü§ñ Assistant finished speaking\")\n",
    "            print(\"üé§ Ready for next input...\")\n",
    "\n",
    "        elif event.type == ServerEventType.RESPONSE_DONE:\n",
    "            logger.info(\"‚úÖ Response complete\")\n",
    "            self._active_response = False\n",
    "            self._response_api_done = True\n",
    "\n",
    "            # Execute pending function call if arguments are ready\n",
    "            if self._pending_function_call and \"arguments\" in self._pending_function_call:\n",
    "                await self._execute_function_call(self._pending_function_call)\n",
    "                self._pending_function_call = None\n",
    "\n",
    "        elif event.type == ServerEventType.ERROR:\n",
    "            msg = event.error.message\n",
    "            if \"Cancellation failed: no active response\" in msg:\n",
    "                logger.debug(\"Benign cancellation error: %s\", msg)\n",
    "            else:\n",
    "                logger.error(\"‚ùå VoiceLive error: %s\", msg)\n",
    "                print(f\"Error: {msg}\")\n",
    "\n",
    "        elif event.type == ServerEventType.CONVERSATION_ITEM_CREATED:\n",
    "            logger.debug(\"Conversation item created: %s\", event.item.id)\n",
    "\n",
    "            if event.item.type == ItemType.FUNCTION_CALL:\n",
    "                function_call_item = event.item\n",
    "                self._pending_function_call = {\n",
    "                    \"name\": function_call_item.name,\n",
    "                    \"call_id\": function_call_item.call_id,\n",
    "                    \"previous_item_id\": function_call_item.id\n",
    "                }\n",
    "                print(f\"üîß Calling function: {function_call_item.name}\")\n",
    "                logger.info(f\"Function call detected: {function_call_item.name} with call_id: {function_call_item.call_id}\")\n",
    "\n",
    "        elif event.type == ServerEventType.RESPONSE_FUNCTION_CALL_ARGUMENTS_DONE:\n",
    "            if self._pending_function_call and event.call_id == self._pending_function_call[\"call_id\"]:\n",
    "                logger.info(f\"Function arguments received: {event.arguments}\")\n",
    "                self._pending_function_call[\"arguments\"] = event.arguments\n",
    "\n",
    "    async def _execute_function_call(self, function_call_info):\n",
    "        \"\"\"Execute a function call and send the result back to the conversation.\"\"\"\n",
    "        conn = self.connection\n",
    "        assert conn is not None, \"Connection must be established\"\n",
    "\n",
    "        function_name = function_call_info[\"name\"]\n",
    "        call_id = function_call_info[\"call_id\"]\n",
    "        previous_item_id = function_call_info[\"previous_item_id\"]\n",
    "        arguments = function_call_info[\"arguments\"]\n",
    "\n",
    "        try:\n",
    "            if function_name in AVAILABLE_FUNCTIONS:\n",
    "                logger.info(f\"Executing function: {function_name}\")\n",
    "                result = AVAILABLE_FUNCTIONS[function_name](arguments)\n",
    "\n",
    "                function_output = FunctionCallOutputItem(call_id=call_id, output=json.dumps(result))\n",
    "\n",
    "                # Send result back to conversation\n",
    "                await conn.conversation.item.create(previous_item_id=previous_item_id, item=function_output)\n",
    "                logger.info(f\"Function result sent: {result}\")\n",
    "                print(f\"‚úÖ Function {function_name} completed\")\n",
    "\n",
    "                # Request new response to process the function result\n",
    "                await conn.response.create()\n",
    "                logger.info(\"Requested new response with function result\")\n",
    "\n",
    "            else:\n",
    "                logger.error(f\"Unknown function: {function_name}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error executing function {function_name}: {e}\")\n",
    "\n",
    "print(\"AsyncFunctionCallingClient class defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0218a352",
   "metadata": {},
   "source": [
    "## Check Audio System\n",
    "\n",
    "Verify that audio input and output devices are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d0ba8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check audio system\n",
    "try:\n",
    "    p = pyaudio.PyAudio()\n",
    "    \n",
    "    # Check for input devices\n",
    "    input_devices = [\n",
    "        i\n",
    "        for i in range(p.get_device_count())\n",
    "        if cast(Union[int, float], p.get_device_info_by_index(i).get(\"maxInputChannels\", 0) or 0) > 0\n",
    "    ]\n",
    "    \n",
    "    # Check for output devices\n",
    "    output_devices = [\n",
    "        i\n",
    "        for i in range(p.get_device_count())\n",
    "        if cast(Union[int, float], p.get_device_info_by_index(i).get(\"maxOutputChannels\", 0) or 0) > 0\n",
    "    ]\n",
    "    \n",
    "    p.terminate()\n",
    "\n",
    "    if not input_devices:\n",
    "        print(\"‚ùå No audio input devices found. Please check your microphone.\")\n",
    "        audio_ok = False\n",
    "    elif not output_devices:\n",
    "        print(\"‚ùå No audio output devices found. Please check your speakers.\")\n",
    "        audio_ok = False\n",
    "    else:\n",
    "        print(f\"‚úÖ Found {len(input_devices)} input device(s) and {len(output_devices)} output device(s)\")\n",
    "        audio_ok = True\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Audio system check failed: {e}\")\n",
    "    audio_ok = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3cad216",
   "metadata": {},
   "source": [
    "## Run the Voice Assistant\n",
    "\n",
    "Start the voice assistant with function calling capabilities.\n",
    "\n",
    "**Available voice commands:**\n",
    "- \"What's the current time?\"\n",
    "- \"What's the weather in Seattle?\"\n",
    "\n",
    "Press Ctrl+C or interrupt the kernel to stop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61e680f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate credentials\n",
    "if not API_KEY and not USE_TOKEN_CREDENTIAL:\n",
    "    print(\"‚ùå Error: No authentication provided\")\n",
    "    print(\"Please provide an API key in .env file or set USE_TOKEN_CREDENTIAL = True\")\n",
    "else:\n",
    "    # Create credential\n",
    "    if USE_TOKEN_CREDENTIAL:\n",
    "        credential = AzureCliCredential()\n",
    "        print(\"Using Azure token credential\")\n",
    "    else:\n",
    "        credential = AzureKeyCredential(API_KEY)\n",
    "        print(\"Using API key credential\")\n",
    "\n",
    "    # Create and start voice assistant with function calling\n",
    "    client = AsyncFunctionCallingClient(\n",
    "        endpoint=ENDPOINT,\n",
    "        credential=credential,\n",
    "        model=MODEL,\n",
    "        voice=VOICE,\n",
    "        instructions=INSTRUCTIONS,\n",
    "    )\n",
    "\n",
    "    print(\"\\nüéôÔ∏è  Voice Assistant with Function Calling - Azure VoiceLive SDK\")\n",
    "    print(\"=\" * 65)\n",
    "\n",
    "    try:\n",
    "        await client.start()\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nüëã Voice assistant shut down. Goodbye!\")\n",
    "    except asyncio.CancelledError:\n",
    "        print(\"\\nüëã Session cancelled. Voice assistant shut down.\")\n",
    "    except Exception as e:\n",
    "        logger.exception(\"Fatal error\")\n",
    "        print(f\"Fatal Error: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
