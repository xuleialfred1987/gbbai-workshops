{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4630cb5",
   "metadata": {},
   "source": [
    "## 1. å®‰è£…ä¾èµ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3a026c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q redis pandas openpyxl openai python-dotenv numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29829f04",
   "metadata": {},
   "source": [
    "## 2. é…ç½®ç¯å¢ƒå˜é‡\n",
    "\n",
    "è¯·åœ¨ `.env` æ–‡ä»¶ä¸­é…ç½®ä»¥ä¸‹å˜é‡ï¼Œæˆ–ç›´æ¥åœ¨ä¸‹æ–¹ä¿®æ”¹ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933350cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv(\"../.env\", override=True)\n",
    "\n",
    "# ============================================================\n",
    "# AZURE MANAGED REDIS é…ç½®\n",
    "# ============================================================\n",
    "REDIS_HOST = \"xle-redis2.eastus.redis.azure.net\"\n",
    "REDIS_PORT = 10000\n",
    "REDIS_PASSWORD = os.getenv(\"AZURE_REDIS_PASSWORD\", \"<your-access-key-here>\")  # ä» Azure Portal Access Keys è·å–\n",
    "\n",
    "# ============================================================\n",
    "# AZURE OPENAI é…ç½® (ç”¨äºç”Ÿæˆ Embeddings)\n",
    "# ============================================================\n",
    "AZURE_OPENAI_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "AZURE_OPENAI_API_KEY = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "EMBEDDING_MODEL = os.getenv(\"AZURE_OPENAI_EMBEDDING_MODEL\", \"text-embedding-ada-002\")\n",
    "EMBEDDING_DIMENSIONS = 1536  # ada-002 çš„ç»´åº¦\n",
    "\n",
    "# ============================================================\n",
    "# REDIS ç´¢å¼•é…ç½®\n",
    "# ============================================================\n",
    "INDEX_NAME = \"product_index\"\n",
    "\n",
    "# æ˜¾ç¤ºé…ç½®\n",
    "print(\"ğŸ“ é…ç½®ä¿¡æ¯:\")\n",
    "print(f\"   Redis Host: {REDIS_HOST}:{REDIS_PORT}\")\n",
    "print(f\"   Redis Password: {'å·²è®¾ç½®' if REDIS_PASSWORD and REDIS_PASSWORD != '<your-access-key-here>' else 'âŒ æœªè®¾ç½®'}\")\n",
    "print(f\"   OpenAI Endpoint: {AZURE_OPENAI_ENDPOINT}\")\n",
    "print(f\"   Embedding Model: {EMBEDDING_MODEL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f31679",
   "metadata": {},
   "source": [
    "## 3. è¯»å– Excel æ•°æ®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776c6274",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# è¯»å– Excel æ–‡ä»¶\n",
    "excel_path = \"./m1Id_tw_100.xlsx\"\n",
    "df = pd.read_excel(excel_path)\n",
    "\n",
    "# å°†åˆ—åè½¬ä¸ºå°å†™\n",
    "df.columns = [col.lower().strip() for col in df.columns]\n",
    "\n",
    "print(f\"âœ… è¯»å–äº† {len(df)} æ¡è®°å½•\")\n",
    "print(f\"ğŸ“‹ åˆ—å: {list(df.columns)}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf23528",
   "metadata": {},
   "source": [
    "## 4. å‡†å¤‡æ–‡æ¡£æ•°æ®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef20b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "def prepare_documents(df):\n",
    "    \"\"\"å°† DataFrame è½¬æ¢ä¸ºæ–‡æ¡£åˆ—è¡¨\"\"\"\n",
    "    documents = []\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        # æå–å­—æ®µï¼Œå¤„ç†ç©ºå€¼\n",
    "        url = str(row.get(\"url\", \"\")) if pd.notna(row.get(\"url\")) else \"\"\n",
    "        name = str(row.get(\"name\", \"\")) if pd.notna(row.get(\"name\")) else \"\"\n",
    "        m1id = str(row.get(\"m1id\", \"\")) if pd.notna(row.get(\"m1id\")) else \"\"\n",
    "        spec = str(row.get(\"spec\", \"\")) if pd.notna(row.get(\"spec\")) else \"\"\n",
    "        onlinedt = str(row.get(\"onlinedt\", \"\")) if pd.notna(row.get(\"onlinedt\")) else \"\"\n",
    "        m1name = str(row.get(\"m1name\", \"\")) if pd.notna(row.get(\"m1name\")) else \"\"\n",
    "        globalname = str(row.get(\"globalname\", \"\")) if pd.notna(row.get(\"globalname\")) else \"\"\n",
    "        productline = str(row.get(\"productline\", \"\")) if pd.notna(row.get(\"productline\")) else \"\"\n",
    "        aiproductline = str(row.get(\"aiproductline\", \"\")) if pd.notna(row.get(\"aiproductline\")) else \"\"\n",
    "        \n",
    "        # æ„å»ºç”¨äºæœç´¢çš„å†…å®¹æ–‡æœ¬\n",
    "        content = f\"äº§å“åç§°: {name}\\nè§„æ ¼: {spec}\\näº§å“çº¿: {productline}\\nAIäº§å“çº¿: {aiproductline}\"\n",
    "        \n",
    "        # æ„å»ºå®Œæ•´å…ƒæ•°æ®\n",
    "        metadata = f\"m1id: {m1id}, m1name: {m1name}, globalname: {globalname}, url: {url}\"\n",
    "        \n",
    "        document = {\n",
    "            \"id\": str(uuid.uuid4()),\n",
    "            \"name\": name,\n",
    "            \"m1id\": m1id,\n",
    "            \"content\": content,\n",
    "            \"metadata\": metadata,\n",
    "            \"url\": url,\n",
    "            \"productline\": productline,\n",
    "        }\n",
    "        documents.append(document)\n",
    "    \n",
    "    return documents\n",
    "\n",
    "documents = prepare_documents(df)\n",
    "print(f\"âœ… å‡†å¤‡äº† {len(documents)} ä¸ªæ–‡æ¡£\")\n",
    "print(\"\\nğŸ“„ ç¤ºä¾‹æ–‡æ¡£:\")\n",
    "documents[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e453a5",
   "metadata": {},
   "source": [
    "## 5. ç”Ÿæˆ Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99962bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "\n",
    "# åˆå§‹åŒ– Azure OpenAI å®¢æˆ·ç«¯\n",
    "openai_client = AzureOpenAI(\n",
    "    api_key=AZURE_OPENAI_API_KEY,\n",
    "    api_version=\"2024-02-01\",\n",
    "    azure_endpoint=AZURE_OPENAI_ENDPOINT\n",
    ")\n",
    "\n",
    "def generate_embeddings(texts: list, batch_size: int = 100) -> list:\n",
    "    \"\"\"æ‰¹é‡ç”Ÿæˆæ–‡æœ¬çš„ embedding å‘é‡\"\"\"\n",
    "    embeddings = []\n",
    "    \n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch = texts[i:i + batch_size]\n",
    "        response = openai_client.embeddings.create(\n",
    "            input=batch,\n",
    "            model=EMBEDDING_MODEL\n",
    "        )\n",
    "        batch_embeddings = [e.embedding for e in response.data]\n",
    "        embeddings.extend(batch_embeddings)\n",
    "        print(f\"   ç”Ÿæˆ embeddings: {i + len(batch)}/{len(texts)}\")\n",
    "    \n",
    "    return embeddings\n",
    "\n",
    "# æå–å†…å®¹æ–‡æœ¬\n",
    "content_texts = [doc[\"content\"] for doc in documents]\n",
    "\n",
    "print(\"ğŸ”„ æ­£åœ¨ç”Ÿæˆ embeddings...\")\n",
    "embeddings = generate_embeddings(content_texts)\n",
    "print(f\"\\nâœ… ç”Ÿæˆäº† {len(embeddings)} ä¸ª embeddingsï¼Œç»´åº¦: {len(embeddings[0])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98eee232",
   "metadata": {},
   "source": [
    "## 6. è¿æ¥ Azure Managed Redis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a2577b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import redis\n",
    "\n",
    "# è¿æ¥åˆ° Azure Managed Redis (TLS)\n",
    "redis_client = redis.Redis(\n",
    "    host=REDIS_HOST,\n",
    "    port=REDIS_PORT,\n",
    "    password=REDIS_PASSWORD,\n",
    "    ssl=True,\n",
    "    ssl_cert_reqs=None,  # å¯¹äº Azure Managed Redis\n",
    "    decode_responses=False,  # å‘é‡æ•°æ®éœ€è¦ bytes\n",
    ")\n",
    "\n",
    "# æµ‹è¯•è¿æ¥\n",
    "try:\n",
    "    pong = redis_client.ping()\n",
    "    print(f\"âœ… Redis è¿æ¥æˆåŠŸ! PING: {pong}\")\n",
    "    info = redis_client.info(\"server\")\n",
    "    print(f\"   Redis ç‰ˆæœ¬: {info.get('redis_version', 'unknown')}\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Redis è¿æ¥å¤±è´¥: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48fd9462",
   "metadata": {},
   "source": [
    "## 7. åˆ›å»º RediSearch å‘é‡ç´¢å¼•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e07694b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from redis.commands.search.field import TextField, TagField, VectorField\n",
    "\n",
    "# ä¸åŒç‰ˆæœ¬çš„ redis-py è·¯å¾„ä¸åŒ\n",
    "try:\n",
    "    from redis.commands.search.indexDefinition import IndexDefinition, IndexType\n",
    "except ImportError:\n",
    "    from redis.commands.search.index_definition import IndexDefinition, IndexType\n",
    "\n",
    "def create_vector_index(client, index_name: str, vector_dim: int = 1536):\n",
    "    \"\"\"åˆ›å»º RediSearch å‘é‡ç´¢å¼•\"\"\"\n",
    "    \n",
    "    # æ£€æŸ¥ç´¢å¼•æ˜¯å¦å·²å­˜åœ¨\n",
    "    try:\n",
    "        client.ft(index_name).info()\n",
    "        print(f\"âš ï¸ ç´¢å¼• '{index_name}' å·²å­˜åœ¨ï¼Œåˆ é™¤å¹¶é‡å»º...\")\n",
    "        client.ft(index_name).dropindex(delete_documents=True)\n",
    "    except:\n",
    "        pass  # ç´¢å¼•ä¸å­˜åœ¨\n",
    "    \n",
    "    # å®šä¹‰ç´¢å¼• schema\n",
    "    schema = [\n",
    "        TextField(\"name\", weight=2.0),           # äº§å“åç§°ï¼Œæƒé‡æ›´é«˜\n",
    "        TextField(\"content\"),                    # å†…å®¹æ–‡æœ¬\n",
    "        TextField(\"metadata\"),                   # å…ƒæ•°æ®\n",
    "        TagField(\"productline\"),                 # äº§å“çº¿ (ç”¨äºè¿‡æ»¤)\n",
    "        TextField(\"url\"),                        # URL\n",
    "        VectorField(\n",
    "            \"embedding\",\n",
    "            \"HNSW\",                              # ä½¿ç”¨ HNSW ç®—æ³•\n",
    "            {\n",
    "                \"TYPE\": \"FLOAT32\",\n",
    "                \"DIM\": vector_dim,\n",
    "                \"DISTANCE_METRIC\": \"COSINE\",     # ä½™å¼¦ç›¸ä¼¼åº¦\n",
    "                \"M\": 16,                          # HNSW å‚æ•°\n",
    "                \"EF_CONSTRUCTION\": 200,\n",
    "            }\n",
    "        ),\n",
    "    ]\n",
    "    \n",
    "    # ç´¢å¼•å®šä¹‰ - ä½¿ç”¨ hash tag {doc} ç¡®ä¿æ‰€æœ‰ key åœ¨åŒä¸€ä¸ª slot\n",
    "    # è¿™å¯¹äº Redis Cluster æ¨¡å¼(Enterprise)æ˜¯å¿…éœ€çš„\n",
    "    definition = IndexDefinition(\n",
    "        prefix=[\"{doc}:\"],\n",
    "        index_type=IndexType.HASH\n",
    "    )\n",
    "    \n",
    "    # åˆ›å»ºç´¢å¼•\n",
    "    client.ft(index_name).create_index(\n",
    "        fields=schema,\n",
    "        definition=definition\n",
    "    )\n",
    "    \n",
    "    print(f\"âœ… ç´¢å¼• '{index_name}' åˆ›å»ºæˆåŠŸ!\")\n",
    "\n",
    "# åˆ›å»ºç´¢å¼•\n",
    "create_vector_index(redis_client, INDEX_NAME, EMBEDDING_DIMENSIONS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19f0a50",
   "metadata": {},
   "source": [
    "## 8. å†™å…¥æ–‡æ¡£å’Œå‘é‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06bb1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def upload_documents(client, documents: list, embeddings: list):\n",
    "    \"\"\"ä¸Šä¼ æ–‡æ¡£å’Œå‘é‡åˆ° Redis (å…¼å®¹ Redis Cluster æ¨¡å¼)\"\"\"\n",
    "    \n",
    "    # å¯¹äº Redis Clusterï¼Œä½¿ç”¨ hash tag {doc} ç¡®ä¿æ‰€æœ‰ key åœ¨åŒä¸€ä¸ª slot\n",
    "    # è¿™æ · pipeline æ‰èƒ½æ­£å¸¸å·¥ä½œ\n",
    "    \n",
    "    pipeline = client.pipeline(transaction=False)  # ç¦ç”¨äº‹åŠ¡æ¨¡å¼ï¼Œé¿å…è·¨ slot é—®é¢˜\n",
    "    \n",
    "    for i, (doc, embedding) in enumerate(zip(documents, embeddings)):\n",
    "        # ä½¿ç”¨ hash tag {doc} - æ‰€æœ‰ key éƒ½ä¼š hash åˆ°åŒä¸€ä¸ª slot\n",
    "        key = f\"{{doc}}:{doc['id']}\"\n",
    "        \n",
    "        # å°† embedding è½¬æ¢ä¸º bytes\n",
    "        embedding_bytes = np.array(embedding, dtype=np.float32).tobytes()\n",
    "        \n",
    "        # å­˜å‚¨ä¸º Hash\n",
    "        pipeline.hset(\n",
    "            key,\n",
    "            mapping={\n",
    "                \"id\": doc[\"id\"],\n",
    "                \"name\": doc[\"name\"],\n",
    "                \"content\": doc[\"content\"],\n",
    "                \"metadata\": doc[\"metadata\"],\n",
    "                \"productline\": doc[\"productline\"],\n",
    "                \"url\": doc[\"url\"],\n",
    "                \"embedding\": embedding_bytes,\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        # æ¯ 50 æ¡æ‰§è¡Œä¸€æ¬¡ (è¾ƒå°æ‰¹æ¬¡æ›´ç¨³å®š)\n",
    "        if (i + 1) % 50 == 0:\n",
    "            pipeline.execute()\n",
    "            pipeline = client.pipeline(transaction=False)\n",
    "            print(f\"   å·²ä¸Šä¼ : {i + 1}/{len(documents)}\")\n",
    "    \n",
    "    # æ‰§è¡Œå‰©ä½™çš„\n",
    "    pipeline.execute()\n",
    "    print(f\"âœ… ä¸Šä¼ å®Œæˆ: {len(documents)} ä¸ªæ–‡æ¡£\")\n",
    "\n",
    "print(\"ğŸ”„ æ­£åœ¨ä¸Šä¼ æ–‡æ¡£åˆ° Redis...\")\n",
    "upload_documents(redis_client, documents, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882f86c8",
   "metadata": {},
   "source": [
    "## 9. éªŒè¯ç´¢å¼•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81791d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è·å–ç´¢å¼•ä¿¡æ¯\n",
    "index_info = redis_client.ft(INDEX_NAME).info()\n",
    "\n",
    "print(\"ğŸ“Š ç´¢å¼•ä¿¡æ¯:\")\n",
    "print(f\"   ç´¢å¼•åç§°: {index_info.get('index_name', INDEX_NAME)}\")\n",
    "print(f\"   æ–‡æ¡£æ•°é‡: {index_info.get('num_docs', 0)}\")\n",
    "\n",
    "# ç´¢å¼•å¤§å°å¯èƒ½æ˜¯å­—ç¬¦ä¸²ï¼Œéœ€è¦è½¬æ¢\n",
    "inverted_sz = index_info.get('inverted_sz_mb', 0)\n",
    "if isinstance(inverted_sz, str):\n",
    "    inverted_sz = float(inverted_sz) if inverted_sz else 0\n",
    "print(f\"   ç´¢å¼•å¤§å°: {inverted_sz:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8428961",
   "metadata": {},
   "source": [
    "## 10. å‘é‡ç›¸ä¼¼åº¦æœç´¢"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9358f6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from redis.commands.search.query import Query\n",
    "\n",
    "def vector_search(client, query_text: str, index_name: str, top_k: int = 5):\n",
    "    \"\"\"\n",
    "    æ‰§è¡Œå‘é‡ç›¸ä¼¼åº¦æœç´¢\n",
    "    \n",
    "    Args:\n",
    "        client: Redis å®¢æˆ·ç«¯\n",
    "        query_text: æŸ¥è¯¢æ–‡æœ¬\n",
    "        index_name: ç´¢å¼•åç§°\n",
    "        top_k: è¿”å›ç»“æœæ•°é‡\n",
    "    \n",
    "    Returns:\n",
    "        æœç´¢ç»“æœåˆ—è¡¨\n",
    "    \"\"\"\n",
    "    # ç”ŸæˆæŸ¥è¯¢æ–‡æœ¬çš„ embedding\n",
    "    response = openai_client.embeddings.create(\n",
    "        input=[query_text],\n",
    "        model=EMBEDDING_MODEL\n",
    "    )\n",
    "    query_embedding = response.data[0].embedding\n",
    "    query_vector = np.array(query_embedding, dtype=np.float32).tobytes()\n",
    "    \n",
    "    # æ„å»º KNN å‘é‡æœç´¢æŸ¥è¯¢\n",
    "    # è¯­æ³•: *=>[KNN K @field $param AS score]\n",
    "    query = (\n",
    "        Query(f\"*=>[KNN {top_k} @embedding $query_vec AS score]\")\n",
    "        .sort_by(\"score\")\n",
    "        .return_fields(\"name\", \"content\", \"metadata\", \"productline\", \"url\", \"score\")\n",
    "        .dialect(2)\n",
    "    )\n",
    "    \n",
    "    # æ‰§è¡Œæœç´¢\n",
    "    results = client.ft(index_name).search(\n",
    "        query,\n",
    "        query_params={\"query_vec\": query_vector}\n",
    "    )\n",
    "    \n",
    "    return results\n",
    "\n",
    "# æµ‹è¯•æœç´¢\n",
    "test_query = \"å·¥ä¸šç”µè„‘\"\n",
    "print(f\"ğŸ” æœç´¢: '{test_query}'\\n\")\n",
    "\n",
    "results = vector_search(redis_client, test_query, INDEX_NAME, top_k=5)\n",
    "\n",
    "print(f\"æ‰¾åˆ° {results.total} ä¸ªç»“æœ:\\n\")\n",
    "for i, doc in enumerate(results.docs, 1):\n",
    "    score = float(doc.score) if hasattr(doc, 'score') else 0\n",
    "    name = doc.name.decode() if isinstance(doc.name, bytes) else doc.name\n",
    "    content = doc.content.decode() if isinstance(doc.content, bytes) else doc.content\n",
    "    \n",
    "    print(f\"--- ç»“æœ {i} (ç›¸ä¼¼åº¦: {1-score:.4f}) ---\")\n",
    "    print(f\"åç§°: {name}\")\n",
    "    print(f\"å†…å®¹: {content[:200]}...\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba2bbd8",
   "metadata": {},
   "source": [
    "## 11. æ··åˆæœç´¢ (å‘é‡ + è¿‡æ»¤)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d566ea47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_search(client, query_text: str, index_name: str, \n",
    "                  productline_filter: str = None, top_k: int = 5):\n",
    "    \"\"\"\n",
    "    æ··åˆæœç´¢: å‘é‡æœç´¢ + å…ƒæ•°æ®è¿‡æ»¤\n",
    "    \"\"\"\n",
    "    # ç”ŸæˆæŸ¥è¯¢ embedding\n",
    "    response = openai_client.embeddings.create(\n",
    "        input=[query_text],\n",
    "        model=EMBEDDING_MODEL\n",
    "    )\n",
    "    query_embedding = response.data[0].embedding\n",
    "    query_vector = np.array(query_embedding, dtype=np.float32).tobytes()\n",
    "    \n",
    "    # æ„å»ºå¸¦è¿‡æ»¤çš„æŸ¥è¯¢\n",
    "    if productline_filter:\n",
    "        # è¿‡æ»¤ç‰¹å®šäº§å“çº¿\n",
    "        query_str = f\"(@productline:{{{productline_filter}}})=>[KNN {top_k} @embedding $query_vec AS score]\"\n",
    "    else:\n",
    "        query_str = f\"*=>[KNN {top_k} @embedding $query_vec AS score]\"\n",
    "    \n",
    "    query = (\n",
    "        Query(query_str)\n",
    "        .sort_by(\"score\")\n",
    "        .return_fields(\"name\", \"content\", \"productline\", \"score\")\n",
    "        .dialect(2)\n",
    "    )\n",
    "    \n",
    "    results = client.ft(index_name).search(\n",
    "        query,\n",
    "        query_params={\"query_vec\": query_vector}\n",
    "    )\n",
    "    \n",
    "    return results\n",
    "\n",
    "# æµ‹è¯•æ··åˆæœç´¢\n",
    "test_query = \"åµŒå…¥å¼ç³»ç»Ÿ\"\n",
    "print(f\"ğŸ” æ··åˆæœç´¢: '{test_query}'\\n\")\n",
    "\n",
    "results = hybrid_search(redis_client, test_query, INDEX_NAME, top_k=3)\n",
    "\n",
    "for i, doc in enumerate(results.docs, 1):\n",
    "    score = float(doc.score) if hasattr(doc, 'score') else 0\n",
    "    name = doc.name.decode() if isinstance(doc.name, bytes) else doc.name\n",
    "    \n",
    "    print(f\"{i}. {name} (ç›¸ä¼¼åº¦: {1-score:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227466f4",
   "metadata": {},
   "source": [
    "## 12. RAG é—®ç­”å‡½æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51f7911",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_query(question: str, top_k: int = 3) -> str:\n",
    "    \"\"\"\n",
    "    RAG é—®ç­”: æ£€ç´¢ç›¸å…³æ–‡æ¡£å¹¶ç”Ÿæˆå›ç­”\n",
    "    \n",
    "    Args:\n",
    "        question: ç”¨æˆ·é—®é¢˜\n",
    "        top_k: æ£€ç´¢æ–‡æ¡£æ•°é‡\n",
    "    \n",
    "    Returns:\n",
    "        AI ç”Ÿæˆçš„å›ç­”\n",
    "    \"\"\"\n",
    "    # 1. å‘é‡æœç´¢æ£€ç´¢ç›¸å…³æ–‡æ¡£\n",
    "    results = vector_search(redis_client, question, INDEX_NAME, top_k=top_k)\n",
    "    \n",
    "    # 2. æ„å»ºä¸Šä¸‹æ–‡\n",
    "    context_parts = []\n",
    "    sources = []\n",
    "    \n",
    "    for doc in results.docs:\n",
    "        name = doc.name.decode() if isinstance(doc.name, bytes) else doc.name\n",
    "        content = doc.content.decode() if isinstance(doc.content, bytes) else doc.content\n",
    "        metadata = doc.metadata.decode() if isinstance(doc.metadata, bytes) else doc.metadata\n",
    "        \n",
    "        context_parts.append(f\"äº§å“: {name}\\n{content}\\n{metadata}\")\n",
    "        sources.append(name)\n",
    "    \n",
    "    context = \"\\n\\n---\\n\\n\".join(context_parts)\n",
    "    \n",
    "    # 3. ä½¿ç”¨ LLM ç”Ÿæˆå›ç­”\n",
    "    system_prompt = \"\"\"ä½ æ˜¯ä¸€ä¸ªäº§å“ä¸“å®¶åŠ©æ‰‹ã€‚æ ¹æ®æä¾›çš„äº§å“ä¿¡æ¯å›ç­”ç”¨æˆ·é—®é¢˜ã€‚\n",
    "å¦‚æœä¿¡æ¯ä¸è¶³ä»¥å›ç­”é—®é¢˜ï¼Œè¯·è¯šå®è¯´æ˜ã€‚è¯·ç”¨ä¸­æ–‡å›ç­”ã€‚\"\"\"\n",
    "    \n",
    "    user_prompt = f\"\"\"æ ¹æ®ä»¥ä¸‹äº§å“ä¿¡æ¯å›ç­”é—®é¢˜ï¼š\n",
    "\n",
    "äº§å“ä¿¡æ¯ï¼š\n",
    "{context}\n",
    "\n",
    "é—®é¢˜ï¼š{question}\n",
    "\n",
    "è¯·æä¾›è¯¦ç»†çš„å›ç­”ï¼š\"\"\"\n",
    "    \n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=\"gpt-4.1\",  # æˆ–æ‚¨çš„éƒ¨ç½²åç§°\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ],\n",
    "        temperature=0.7,\n",
    "        max_tokens=500\n",
    "    )\n",
    "    \n",
    "    answer = response.choices[0].message.content\n",
    "    \n",
    "    return {\n",
    "        \"answer\": answer,\n",
    "        \"sources\": sources\n",
    "    }\n",
    "\n",
    "# æµ‹è¯• RAG é—®ç­”\n",
    "question = \"è¯·æ¨èä¸€æ¬¾é€‚åˆå·¥ä¸šè‡ªåŠ¨åŒ–çš„äº§å“\"\n",
    "print(f\"â“ é—®é¢˜: {question}\\n\")\n",
    "\n",
    "result = rag_query(question)\n",
    "\n",
    "print(f\"ğŸ’¬ å›ç­”:\\n{result['answer']}\")\n",
    "print(f\"\\nğŸ“š å‚è€ƒæ¥æº: {', '.join(result['sources'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4ba0de",
   "metadata": {},
   "source": [
    "## 13. æ¸…ç†èµ„æº (å¯é€‰)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba382c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¦‚éœ€åˆ é™¤ç´¢å¼•å’Œæ•°æ®ï¼Œå–æ¶ˆä¸‹é¢çš„æ³¨é‡Šå¹¶è¿è¡Œ\n",
    "\n",
    "# redis_client.ft(INDEX_NAME).dropindex(delete_documents=True)\n",
    "# print(f\"âœ… ç´¢å¼• '{INDEX_NAME}' å·²åˆ é™¤\")\n",
    "\n",
    "print(\"â„¹ï¸ å¦‚éœ€æ¸…ç†ï¼Œè¯·å–æ¶ˆä¸Šé¢ä»£ç çš„æ³¨é‡Š\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1f8281",
   "metadata": {},
   "source": [
    "## ğŸ“‹ æ€»ç»“\n",
    "\n",
    "æœ¬ notebook æ¼”ç¤ºäº†ï¼š\n",
    "\n",
    "1. âœ… ä» Excel è¯»å–äº§å“æ•°æ®\n",
    "2. âœ… ä½¿ç”¨ Azure OpenAI ç”Ÿæˆ embeddings\n",
    "3. âœ… è¿æ¥ Azure Managed Redis (Enterprise + RediSearch)\n",
    "4. âœ… åˆ›å»º HNSW å‘é‡ç´¢å¼•\n",
    "5. âœ… ä¸Šä¼ æ–‡æ¡£å’Œå‘é‡\n",
    "6. âœ… æ‰§è¡Œå‘é‡ç›¸ä¼¼åº¦æœç´¢\n",
    "7. âœ… å®ç° RAG é—®ç­”\n",
    "\n",
    "### ä¸‹ä¸€æ­¥\n",
    "\n",
    "- å°†æœç´¢åŠŸèƒ½é›†æˆåˆ° Voice Assistant\n",
    "- æ·»åŠ æ›´å¤šè¿‡æ»¤æ¡ä»¶\n",
    "- ä¼˜åŒ– embedding å’Œæ£€ç´¢ç­–ç•¥"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
