{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5c1f0fa",
   "metadata": {},
   "source": [
    "# Azure Blob Knowledge Source\n",
    "\n",
    "Use **Azure Blob Knowledge Source** to automatically create a complete indexer pipeline that ingests, chunks, and vectorizes documents from Blob Storage.\n",
    "\n",
    "## üîÑ Workflow\n",
    "\n",
    "```mermaid\n",
    "flowchart LR\n",
    "    subgraph Input[\"üì¶ Input\"]\n",
    "        Blob[\"Blob Storage<br/>PDF/Word/PPT...\"]\n",
    "    end\n",
    "    \n",
    "    subgraph Auto[\"‚öôÔ∏è Auto-created Pipeline\"]\n",
    "        DS[\"Data Source\"]\n",
    "        SK[\"Skillset<br/>Chunking + Image Semanticization\"]\n",
    "        IDX[\"Index<br/>Vector + Text\"]\n",
    "        IXR[\"Indexer\"]\n",
    "        \n",
    "        DS --> IXR\n",
    "        SK --> IXR\n",
    "        IXR --> IDX\n",
    "    end\n",
    "    \n",
    "    subgraph Query[\"üîç Query\"]\n",
    "        KB[\"Knowledge Base\"]\n",
    "        API[\"Agentic Retrieval API\"]\n",
    "        KB --> API\n",
    "    end\n",
    "    \n",
    "    Blob --> DS\n",
    "    IDX --> KB\n",
    "```\n",
    "\n",
    "> üí° Creating a Blob Knowledge Source **automatically creates** Data Source, Skillset, Index, and Indexer - four resources\n",
    "\n",
    "## üìã Table of Contents\n",
    "\n",
    "| Step | Description | Jump to |\n",
    "|------|-------------|---------|\n",
    "| 0Ô∏è‚É£ Install Dependencies | Install necessary Python packages | [View](#install-deps) |\n",
    "| 1Ô∏è‚É£ Initialize Configuration | Configure Azure AI Search, Storage, Azure OpenAI | [View](#init-config) |\n",
    "| 2Ô∏è‚É£ Create Knowledge Source | Auto-create Data Source + Skillset + Index + Indexer | [View](#step1) |\n",
    "| 3Ô∏è‚É£ Create Knowledge Base | Create knowledge base | [View](#step2) |\n",
    "| 4Ô∏è‚É£ Check Ingestion Status | Monitor indexing progress | [View](#step3) |\n",
    "| 5Ô∏è‚É£ Execute Query | Agentic Retrieval query | [View](#step4) |\n",
    "| 6Ô∏è‚É£ View Resource Details | Check auto-created resources | [View](#step5) |\n",
    "| üßπ Cleanup Resources | Delete resources (optional) | [View](#step7) |\n",
    "\n",
    "---\n",
    "\n",
    "## üìä Feature Support\n",
    "\n",
    "| Feature | Configuration | Description |\n",
    "|---------|--------------|-------------|\n",
    "| üìÑ Text Extraction | ‚úÖ Enabled by default | Supports PDF, Word, PPT, etc. |\n",
    "| üî¢ Embedding | ‚úÖ Configure `embedding_model` | For vector search |\n",
    "| üñºÔ∏è Image Semanticization | ‚úÖ Configure `chat_completion_model` + `disable_image_verbalization=False` | GPT-4o generates image descriptions |\n",
    "| üîÑ Incremental Update | ‚úÖ Auto-supported | Only processes changed documents |\n",
    "| üóëÔ∏è Soft Delete Detection | ‚öôÔ∏è Requires configuration | Enable Native Blob Soft Delete |\n",
    "\n",
    "## üîê Authentication Methods\n",
    "\n",
    "| Method | Connection String Format | Description |\n",
    "|--------|--------------------------|-------------|\n",
    "| **RBAC (Recommended)** | `ResourceId=/subscriptions/.../storageAccounts/xxx;` | Use Managed Identity |\n",
    "| **Access Key** | `DefaultEndpointsProtocol=https;AccountName=...;AccountKey=...` | Traditional key method |\n",
    "\n",
    "## ‚ö†Ô∏è Permission Requirements\n",
    "\n",
    "When using RBAC, Azure AI Search's Managed Identity needs:\n",
    "- `Storage Blob Data Reader` - Read Blob content\n",
    "- `Storage Blob Data Contributor` - If writing to Knowledge Store is required\n",
    "\n",
    "---\n",
    "\n",
    "<a id=\"install-deps\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d544fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary Python packages\n",
    "# azure-search-documents: Azure AI Search SDK (requires version 11.7.0b2+ for Knowledge Source support)\n",
    "# azure-identity: Azure authentication\n",
    "# python-dotenv: Environment variable management\n",
    "\n",
    "%pip install azure-search-documents==11.7.0b2 azure-identity python-dotenv -qU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273068c1",
   "metadata": {},
   "source": [
    "<a id=\"init-config\"></a>\n",
    "## 0Ô∏è‚É£ Initialize Configuration\n",
    "\n",
    "Configure Azure AI Search, Storage Account, and Azure OpenAI connection information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cddb6ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from azure.identity import AzureCliCredential, get_bearer_token_provider\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Azure AI Search configuration\n",
    "search_endpoint = os.getenv(\"AZURE_SEARCH_ENDPOINT\")\n",
    "search_api_key = os.getenv(\"AZURE_SEARCH_API_KEY\")\n",
    "\n",
    "# Azure OpenAI configuration\n",
    "azure_openai_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "embedding_model = os.getenv(\"AZURE_OPENAI_EMBEDDING_MODEL\", \"text-embedding-ada-002\")\n",
    "embedding_deployment = os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT\", \"text-embedding-3-large\")\n",
    "gpt_deployment = os.getenv(\"AZURE_OPENAI_DEPLOYMENT\", \"gpt-4o-mini\")\n",
    "\n",
    "# Create SearchIndexClient\n",
    "index_client = SearchIndexClient(\n",
    "    endpoint=search_endpoint,\n",
    "    credential=AzureKeyCredential(search_api_key)\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Azure AI Search: {search_endpoint}\")\n",
    "print(\"\\nüîß Azure OpenAI:\")\n",
    "print(f\"   Endpoint: {azure_openai_endpoint}\")\n",
    "print(f\"   Embedding: {embedding_deployment} ({embedding_model})\")\n",
    "print(f\"   GPT Model: {gpt_deployment}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e885a14",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"step1\"></a>\n",
    "## 1Ô∏è‚É£ Create Blob Knowledge Source\n",
    "\n",
    "This automatically creates Data Source + Skillset + Index + Indexer, completing the entire pipeline configuration with one operation.\n",
    "\n",
    "### Configuration Description\n",
    "\n",
    "| Parameter | Description |\n",
    "|-----------|-------------|\n",
    "| `connection_string` | Storage Account connection string (RBAC or Access Key) |\n",
    "| `container_name` | Blob container name |\n",
    "| `folder_path` | Optional, specify subfolder |\n",
    "| `is_adls_gen2` | Whether using ADLS Gen2 (supports ACL) |\n",
    "| `content_extraction_mode` | `MINIMAL` (default) or `STANDARD` |\n",
    "| `disable_image_verbalization` | `False` enables image semanticization, `True` disables |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6958b17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents.indexes.models import (\n",
    "    AzureBlobKnowledgeSource,\n",
    "    AzureBlobKnowledgeSourceParameters,\n",
    "    KnowledgeSourceIngestionParameters,\n",
    "    KnowledgeSourceContentExtractionMode,\n",
    "    KnowledgeBaseAzureOpenAIModel,\n",
    "    KnowledgeSourceAzureOpenAIVectorizer,\n",
    "    AzureOpenAIVectorizerParameters\n",
    ")\n",
    "\n",
    "# Knowledge Source name\n",
    "blob_ks_name = \"demo2-blob-knowledge-source\"\n",
    "\n",
    "# Storage Account configuration (using RBAC)\n",
    "# ‚ö†Ô∏è Important: RBAC authentication must use \"ResourceId=...;\" format\n",
    "# Read from environment variables, or use default example value\n",
    "storage_account_resource_id = os.getenv(\n",
    "    \"STORAGE_ACCOUNT_RESOURCE_ID\",\n",
    "    \"/subscriptions/{subscription-id}/resourceGroups/{resource-group}/providers/Microsoft.Storage/storageAccounts/{storage-account-name}\"\n",
    ")\n",
    "storage_connection_string = f\"ResourceId={storage_account_resource_id};\"\n",
    "blob_container_name = os.getenv(\"BLOB_CONTAINER_NAME\", \"indexfromblob\")\n",
    "\n",
    "# Azure OpenAI parameters - GPT model (for image semanticization)\n",
    "aoai_chat_params = AzureOpenAIVectorizerParameters(\n",
    "    resource_url=azure_openai_endpoint,\n",
    "    deployment_name=gpt_deployment,\n",
    "    model_name=gpt_deployment\n",
    ")\n",
    "\n",
    "# Azure OpenAI parameters - Embedding model\n",
    "aoai_embedding_params = AzureOpenAIVectorizerParameters(\n",
    "    resource_url=azure_openai_endpoint,\n",
    "    deployment_name=embedding_deployment,\n",
    "    model_name=embedding_model\n",
    ")\n",
    "\n",
    "# Create Blob Knowledge Source\n",
    "blob_knowledge_source = AzureBlobKnowledgeSource(\n",
    "    name=blob_ks_name,\n",
    "    description=\"Knowledge source that auto-ingests, chunks, and vectorizes from Blob Storage\",\n",
    "    azure_blob_parameters=AzureBlobKnowledgeSourceParameters(\n",
    "        # Blob Storage connection\n",
    "        connection_string=storage_connection_string,\n",
    "        container_name=blob_container_name,\n",
    "        folder_path=None,  # Optional: specify subfolder\n",
    "        is_adls_gen2=False,  # Set to True if using ADLS Gen2\n",
    "        \n",
    "        # Data import parameters\n",
    "        ingestion_parameters=KnowledgeSourceIngestionParameters(\n",
    "            # Content extraction mode\n",
    "            content_extraction_mode=KnowledgeSourceContentExtractionMode.MINIMAL,\n",
    "            \n",
    "            # ‚úÖ Enable image semanticization (GPT-4o generates image descriptions)\n",
    "            disable_image_verbalization=False,\n",
    "            chat_completion_model=KnowledgeBaseAzureOpenAIModel(\n",
    "                azure_open_ai_parameters=aoai_chat_params\n",
    "            ),\n",
    "            \n",
    "            # ‚úÖ Embedding model for vector search\n",
    "            embedding_model=KnowledgeSourceAzureOpenAIVectorizer(\n",
    "                azure_open_ai_parameters=aoai_embedding_params\n",
    "            )\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "try:\n",
    "    result = index_client.create_or_update_knowledge_source(knowledge_source=blob_knowledge_source)\n",
    "    print(f\"‚úÖ Blob Knowledge Source '{blob_ks_name}' created successfully!\")\n",
    "    print(\"   Type: azureBlob\")\n",
    "    \n",
    "    print(\"\\nüîß Enabled features:\")\n",
    "    print(\"   - Image semanticization: ‚úÖ Enabled\")\n",
    "    print(f\"   - Embedding: ‚úÖ {embedding_deployment}\")\n",
    "    \n",
    "    print(\"\\nüìã Auto-created resources:\")\n",
    "    if hasattr(result, 'azure_blob_parameters') and result.azure_blob_parameters:\n",
    "        params = result.azure_blob_parameters\n",
    "        cr = getattr(params, 'created_resources', None)\n",
    "        if cr:\n",
    "            # Compatible with both dict and object return formats\n",
    "            if isinstance(cr, dict):\n",
    "                print(f\"   - Data Source: {cr.get('datasource', 'N/A')}\")\n",
    "                print(f\"   - Index: {cr.get('index', 'N/A')}\")\n",
    "                print(f\"   - Skillset: {cr.get('skillset', 'N/A')}\")\n",
    "                print(f\"   - Indexer: {cr.get('indexer', 'N/A')}\")\n",
    "            else:\n",
    "                print(f\"   - Data Source: {getattr(cr, 'datasource', 'N/A')}\")\n",
    "                print(f\"   - Index: {getattr(cr, 'index', 'N/A')}\")\n",
    "                print(f\"   - Skillset: {getattr(cr, 'skillset', 'N/A')}\")\n",
    "                print(f\"   - Indexer: {getattr(cr, 'indexer', 'N/A')}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Creation failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd71574",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"step2\"></a>\n",
    "## 2Ô∏è‚É£ Create Knowledge Base\n",
    "\n",
    "Knowledge Base is the entry point for queries and can be associated with one or more Knowledge Sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fe1544",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents.indexes.models import (\n",
    "    KnowledgeBase,\n",
    "    KnowledgeSourceReference,\n",
    "    KnowledgeBaseAzureOpenAIModel,\n",
    "    AzureOpenAIVectorizerParameters,\n",
    "    KnowledgeRetrievalOutputMode,\n",
    "    KnowledgeRetrievalLowReasoningEffort\n",
    ")\n",
    "\n",
    "# Knowledge Base name\n",
    "blob_kb_name = \"demo2-blob-knowledge-base\"\n",
    "\n",
    "# Azure OpenAI parameters (for answer generation)\n",
    "aoai_kb_params = AzureOpenAIVectorizerParameters(\n",
    "    resource_url=azure_openai_endpoint,\n",
    "    deployment_name=gpt_deployment,\n",
    "    model_name=gpt_deployment\n",
    ")\n",
    "\n",
    "# Create Knowledge Base\n",
    "blob_knowledge_base = KnowledgeBase(\n",
    "    name=blob_kb_name,\n",
    "    description=\"Knowledge base based on Blob Storage documents\",\n",
    "    \n",
    "    # Associate Knowledge Source\n",
    "    knowledge_sources=[KnowledgeSourceReference(name=blob_ks_name)],\n",
    "    \n",
    "    # Retrieval and answer instructions\n",
    "    retrieval_instructions=\"Use this knowledge source to answer questions about stored documents\",\n",
    "    answer_instructions=\"Based on retrieved document content, provide accurate and detailed answers with citations\",\n",
    "    \n",
    "    # Output mode: answer synthesis\n",
    "    output_mode=KnowledgeRetrievalOutputMode.ANSWER_SYNTHESIS,\n",
    "    \n",
    "    # GPT model configuration\n",
    "    models=[KnowledgeBaseAzureOpenAIModel(azure_open_ai_parameters=aoai_kb_params)],\n",
    "    \n",
    "    # Reasoning effort level\n",
    "    retrieval_reasoning_effort=KnowledgeRetrievalLowReasoningEffort()\n",
    ")\n",
    "\n",
    "try:\n",
    "    index_client.create_or_update_knowledge_base(knowledge_base=blob_knowledge_base)\n",
    "    print(f\"‚úÖ Knowledge Base '{blob_kb_name}' created successfully!\")\n",
    "    print(f\"   Associated Knowledge Source: {blob_ks_name}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Creation failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ac88a6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"step3\"></a>\n",
    "## 3Ô∏è‚É£ Check Ingestion Status\n",
    "\n",
    "> ‚ö†Ô∏è Initial ingestion may take several minutes to tens of minutes, depending on document count and size\n",
    "\n",
    "### Indexer Status Description\n",
    "\n",
    "| Status | Description |\n",
    "|--------|-------------|\n",
    "| `inProgress` | Running |\n",
    "| `success` | Completed successfully |\n",
    "| `transientFailure` | Temporary failure (will auto-retry) |\n",
    "| `persistentFailure` | Permanent failure (check configuration) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2d168c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "def check_indexer_status(search_endpoint, api_key, indexer_name):\n",
    "    \"\"\"Get Indexer run status\"\"\"\n",
    "    endpoint = f\"{search_endpoint}/indexers/{indexer_name}/status\"\n",
    "    params = {\"api-version\": \"2025-11-01-preview\"}\n",
    "    headers = {\"api-key\": api_key}\n",
    "    response = requests.get(endpoint, params=params, headers=headers)\n",
    "    return response.json()\n",
    "\n",
    "# Indexer name = Knowledge Source name + \"-indexer\"\n",
    "indexer_name = f\"{blob_ks_name}-indexer\"\n",
    "indexer_status = check_indexer_status(search_endpoint, search_api_key, indexer_name)\n",
    "\n",
    "print(f\"üîÑ Indexer '{indexer_name}' status:\")\n",
    "print(f\"   Overall status: {indexer_status.get('status', 'N/A')}\")\n",
    "\n",
    "if \"lastResult\" in indexer_status:\n",
    "    last_result = indexer_status[\"lastResult\"]\n",
    "    print(\"\\nüìã Last execution:\")\n",
    "    print(f\"   Status: {last_result.get('status', 'N/A')}\")\n",
    "    print(f\"   Start time: {last_result.get('startTime', 'N/A')}\")\n",
    "    print(f\"   End time: {last_result.get('endTime', 'N/A')}\")\n",
    "    print(f\"   ‚úÖ Successfully processed: {last_result.get('itemsProcessed', 0)} documents\")\n",
    "    print(f\"   ‚ùå Failed to process: {last_result.get('itemsFailed', 0)} documents\")\n",
    "    \n",
    "    # Display errors\n",
    "    if last_result.get('errors'):\n",
    "        print(f\"\\n‚ö†Ô∏è Errors ({len(last_result['errors'])} items):\")\n",
    "        for err in last_result['errors'][:3]:\n",
    "            print(f\"   - {err.get('message', 'Unknown')[:100]}\")\n",
    "else:\n",
    "    print(\"   Not yet run\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26057fc2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"step4\"></a>\n",
    "## 4Ô∏è‚É£ Execute Query\n",
    "\n",
    "Use Agentic Retrieval API to query the knowledge base, getting synthesized answers and citation sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889dcb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents.knowledgebases import KnowledgeBaseRetrievalClient\n",
    "from azure.search.documents.knowledgebases.models import (\n",
    "    KnowledgeBaseRetrievalRequest,\n",
    "    KnowledgeBaseMessage,\n",
    "    KnowledgeBaseMessageTextContent,\n",
    "    AzureBlobKnowledgeSourceParams\n",
    ")\n",
    "\n",
    "# Create Knowledge Base client\n",
    "blob_kb_client = KnowledgeBaseRetrievalClient(\n",
    "    endpoint=search_endpoint,\n",
    "    knowledge_base_name=blob_kb_name,\n",
    "    credential=AzureKeyCredential(search_api_key)\n",
    ")\n",
    "\n",
    "# Query question\n",
    "question = \"Show me eval metrics of TabFM\"\n",
    "\n",
    "# Build query request\n",
    "request = KnowledgeBaseRetrievalRequest(\n",
    "    include_activity=True,  # Include activity log\n",
    "    messages=[\n",
    "        KnowledgeBaseMessage(\n",
    "            role=\"user\",\n",
    "            content=[KnowledgeBaseMessageTextContent(text=question)]\n",
    "        )\n",
    "    ],\n",
    "    knowledge_source_params=[\n",
    "        AzureBlobKnowledgeSourceParams(\n",
    "            knowledge_source_name=blob_ks_name,\n",
    "            include_references=True,        # Include references\n",
    "            include_reference_source_data=True  # Include reference source data\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(f\"üîç Query: {question}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "result = blob_kb_client.retrieve(retrieval_request=request)\n",
    "\n",
    "print(\"\\nüìù Answer:\")\n",
    "print(\"-\" * 40)\n",
    "for resp in result.response:\n",
    "    for content in resp.content:\n",
    "        print(content.text)\n",
    "\n",
    "# Display references\n",
    "if result.references:\n",
    "    print(\"\\nüìö Reference sources:\")\n",
    "    for i, ref in enumerate(result.references, 1):\n",
    "        ref_dict = ref.as_dict()\n",
    "        blob_url = ref_dict.get('blob_url', 'N/A')\n",
    "        print(f\"  [{i}] {blob_url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e05229c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"step5\"></a>\n",
    "## 5Ô∏è‚É£ View Activity Log and Reference Details\n",
    "\n",
    "Activity log shows detailed information during the query process, including retrieval, re-ranking, and other steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e679ca3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "if result.activity:\n",
    "    print(\"üìä Activity log:\")\n",
    "    print(\"=\" * 60)\n",
    "    for i, activity in enumerate(result.activity, 1):\n",
    "        act = activity.as_dict()\n",
    "        print(f\"\\nüîπ Step {i}: {act.get('type', 'N/A')}\")\n",
    "        # Print full content\n",
    "        for key, value in act.items():\n",
    "            if key != 'type' and value is not None:\n",
    "                print(f\"   {key}: {value}\")\n",
    "\n",
    "if result.references:\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"üîó Reference sources:\")\n",
    "    print(\"-\" * 60)\n",
    "    for i, ref in enumerate(result.references, 1):\n",
    "        ref_dict = ref.as_dict()\n",
    "        print(f\"\\n  [{i}] {ref_dict.get('blob_url', 'N/A')}\")\n",
    "        for key, value in ref_dict.items():\n",
    "            if key != 'blob_url' and value is not None:\n",
    "                if isinstance(value, str) and len(value) > 300:\n",
    "                    print(f\"      {key}: {value[:300]}...\")\n",
    "                else:\n",
    "                    print(f\"      {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e481eeea",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"step6\"></a>\n",
    "## 6Ô∏è‚É£ View Auto-created Resources\n",
    "\n",
    "Knowledge Source automatically creates the following resources:\n",
    "\n",
    "| Resource | Naming Convention | Description |\n",
    "|----------|-------------------|-------------|\n",
    "| Data Source | `{ks_name}-datasource` | Connects to Blob Storage |\n",
    "| Index | `{ks_name}-index` | Stores document chunks and vectors |\n",
    "| Skillset | `{ks_name}-skillset` | Document processing pipeline |\n",
    "| Indexer | `{ks_name}-indexer` | Executes data import |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9143ef4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def get_knowledge_source_definition(search_endpoint, api_key, ks_name):\n",
    "    endpoint = f\"{search_endpoint}/knowledgesources/{ks_name}\"\n",
    "    params = {\"api-version\": \"2025-11-01-preview\"}\n",
    "    headers = {\"api-key\": api_key}\n",
    "    response = requests.get(endpoint, params=params, headers=headers)\n",
    "    return response.json()\n",
    "\n",
    "ks_definition = get_knowledge_source_definition(search_endpoint, search_api_key, blob_ks_name)\n",
    "\n",
    "if \"azureBlobParameters\" in ks_definition:\n",
    "    blob_params = ks_definition[\"azureBlobParameters\"]\n",
    "    if \"createdResources\" in blob_params:\n",
    "        created = blob_params[\"createdResources\"]\n",
    "        print(\"üîß Auto-created resources:\")\n",
    "        print(f\"   Data Source: {created.get('datasource', 'N/A')}\")\n",
    "        print(f\"   Indexer: {created.get('indexer', 'N/A')}\")\n",
    "        print(f\"   Skillset: {created.get('skillset', 'N/A')}\")\n",
    "        print(f\"   Index: {created.get('index', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2e294d",
   "metadata": {},
   "source": [
    "### 6a. View Skillset (Skills Configuration)\n",
    "\n",
    "Skillset defines the document processing pipeline, including text chunking, image semanticization, embedding, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbdebeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_skillset_definition(search_endpoint, api_key, skillset_name):\n",
    "    endpoint = f\"{search_endpoint}/skillsets/{skillset_name}\"\n",
    "    params = {\"api-version\": \"2025-11-01-preview\"}\n",
    "    headers = {\"api-key\": api_key}\n",
    "    response = requests.get(endpoint, params=params, headers=headers)\n",
    "    return response.json()\n",
    "\n",
    "skillset_name = f\"{blob_ks_name}-skillset\"\n",
    "skillset = get_skillset_definition(search_endpoint, search_api_key, skillset_name)\n",
    "\n",
    "if \"skills\" in skillset:\n",
    "    print(f\"üîß Skillset contains {len(skillset['skills'])} skills:\")\n",
    "    for i, skill in enumerate(skillset.get(\"skills\", []), 1):\n",
    "        skill_type = skill.get(\"@odata.type\", \"Unknown\")\n",
    "        skill_name = skill.get(\"name\", \"N/A\")\n",
    "        print(f\"  [{i}] {skill_name} ({skill_type})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9138c0",
   "metadata": {},
   "source": [
    "### 6b. Incremental Processing and Soft Delete Strategy\n",
    "\n",
    "#### üîÑ Incremental Processing Mechanism\n",
    "\n",
    "| Scenario | Indexer Behavior |\n",
    "|----------|------------------|\n",
    "| File unchanged | ‚è≠Ô∏è Skip |\n",
    "| File content modified | üîÑ Re-process (Upsert) |\n",
    "| New file | ‚ûï Process and add |\n",
    "| File deleted | ‚ùì Depends on soft delete strategy |\n",
    "\n",
    "#### üóëÔ∏è Recommendation: Enable Native Blob Soft Delete\n",
    "\n",
    "After enabling soft delete in Storage Account, Indexer can automatically detect and delete corresponding documents in the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504e308f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datasource_definition(search_endpoint, api_key, datasource_name):\n",
    "    endpoint = f\"{search_endpoint}/datasources/{datasource_name}\"\n",
    "    params = {\"api-version\": \"2025-11-01-preview\"}\n",
    "    headers = {\"api-key\": api_key}\n",
    "    response = requests.get(endpoint, params=params, headers=headers)\n",
    "    return response.json()\n",
    "\n",
    "datasource_name = f\"{blob_ks_name}-datasource\"\n",
    "datasource = get_datasource_definition(search_endpoint, search_api_key, datasource_name)\n",
    "\n",
    "print(\"üóëÔ∏è Deletion detection strategy:\")\n",
    "if \"dataDeletionDetectionPolicy\" in datasource and datasource[\"dataDeletionDetectionPolicy\"]:\n",
    "    print(f\"   ‚úÖ Configured: {datasource['dataDeletionDetectionPolicy'].get('@odata.type')}\")\n",
    "else:\n",
    "    print(\"   ‚ö†Ô∏è Not configured! Recommend enabling Native Blob Soft Delete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb89410",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"step7\"></a>\n",
    "## üßπ Cleanup Resources (Optional)\n",
    "\n",
    "> ‚ö†Ô∏è Deleting Knowledge Source will also delete all auto-created resources (Data Source, Index, Skillset, Indexer)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66fd135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚ö†Ô∏è Deleting Knowledge Source will also delete all auto-created resources!\n",
    "\n",
    "# Uncomment to execute deletion\n",
    "# index_client.delete_knowledge_base(blob_kb_name)\n",
    "# print(f\"‚úÖ Knowledge Base '{blob_kb_name}' deleted\")\n",
    "\n",
    "# index_client.delete_knowledge_source(blob_ks_name)\n",
    "# print(f\"‚úÖ Knowledge Source '{blob_ks_name}' deleted\")\n",
    "# print(\"   Auto-created Data Source, Index, Skillset, Indexer are also deleted\")\n",
    "\n",
    "print(\"üí° To delete resources, uncomment the code above and run\")\n",
    "print(f\"\\nüìã Resources to be deleted:\")\n",
    "print(f\"   - Knowledge Base: {blob_kb_name}\")\n",
    "print(f\"   - Knowledge Source: {blob_ks_name}\")\n",
    "print(f\"   - And its auto-created Data Source, Index, Skillset, Indexer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b399c50",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üì∑ Appendix: Image Processing Mechanism Explained\n",
    "\n",
    "### üîÑ Processing Flow\n",
    "\n",
    "```\n",
    "Blob Storage ‚Üí Document Cracking ‚Üí normalized_images ‚Üí GenAI Prompt Skill ‚Üí Text Description ‚Üí Embedding ‚Üí Index\n",
    "```\n",
    "\n",
    "### üì¶ normalized_images Structure\n",
    "\n",
    "| Field | Description |\n",
    "|-------|-------------|\n",
    "| `data` | BASE64 encoded JPEG image |\n",
    "| `pageNumber` | PDF page number (starting from 1) |\n",
    "| `boundingPolygon` | Image bounding box coordinates on the page |\n",
    "| `width` / `height` | Normalized image dimensions |\n",
    "\n",
    "### ü§ñ Image Description Generation (Image Verbalization)\n",
    "\n",
    "Generate image descriptions via **GenAI Prompt Skill** calling GPT-4o:\n",
    "\n",
    "1. Extract images from PDF/documents\n",
    "2. Send images to GPT-4o\n",
    "3. GPT-4o returns text descriptions of images\n",
    "4. Descriptions are stored as independent chunks in the index\n",
    "\n",
    "### üìç Key Conclusions\n",
    "\n",
    "> üí° Image descriptions are indexed as **complete semantic units** and will not be cut by Text Split!\n",
    "> \n",
    "> Images and text are **stored side by side** as independent chunks\n",
    "\n",
    "### ‚ö†Ô∏è Rate Limit Note\n",
    "\n",
    "If documents contain many images, GPT-4o may trigger Rate Limit. Solutions:\n",
    "- Set `disable_image_verbalization=True` to disable image semanticization\n",
    "- Increase Azure OpenAI TPM quota"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66207bd6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚ö†Ô∏è Appendix: Knowledge Source API Index Schema Limitations\n",
    "\n",
    "**Index auto-created by Knowledge Source API has only 6 fixed fields**:\n",
    "\n",
    "| Field | Type | Description |\n",
    "|-------|------|-------------|\n",
    "| `uid` | String (Key) | Unique identifier |\n",
    "| `snippet_parent_id` | String | Parent document ID for text chunk |\n",
    "| `blob_url` | String | Source document URL (**not** image URL) |\n",
    "| `snippet` | String | Text content or image description |\n",
    "| `image_snippet_parent_id` | String | Parent document ID for image chunk |\n",
    "| `snippet_vector` | Collection(Single) | 1536-dimension vector |\n",
    "\n",
    "### ‚úÖ Can Retrieve vs ‚ùå Cannot Retrieve\n",
    "\n",
    "```\n",
    "‚úÖ Can Retrieve                      ‚ùå Cannot Retrieve\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ snippet (image text     ‚îÇ       ‚îÇ Original image Base64/URL‚îÇ\n",
    "‚îÇ   description)          ‚îÇ       ‚îÇ Page number in PDF       ‚îÇ\n",
    "‚îÇ blob_url (source doc URL)‚îÇ      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       \n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üîß Appendix: What If You Need More Control?\n",
    "\n",
    "### Solution Comparison\n",
    "\n",
    "| Aspect | Knowledge Source API | Traditional Indexer + Skillset |\n",
    "|--------|---------------------|-------------------------------|\n",
    "| **Code Amount** | 1 line to create | Need to configure 4+ components |\n",
    "| **Index Schema** | Fixed 6 fields | Fully customizable |\n",
    "| **Location Metadata** | ‚ùå Not saved | ‚úÖ Configurable |\n",
    "| **Original Images** | ‚ùå Not saved | ‚úÖ Can export |\n",
    "| **Use Cases** | Rapid prototyping, simple apps | Production systems, complex requirements |\n",
    "\n",
    "### If You Need Original Images or Location Information\n",
    "\n",
    "**Solution 1: Trace Back via blob_url (Recommended)**\n",
    "```python\n",
    "# Get source document URL from search results, use Document Intelligence to re-parse\n",
    "from azure.ai.documentintelligence import DocumentIntelligenceClient\n",
    "result = client.begin_analyze_document(\"prebuilt-layout\", {\"urlSource\": blob_url}).result()\n",
    "```\n",
    "\n",
    "**Solution 2: Use Traditional Indexer + Custom Index Schema**\n",
    "\n",
    "Manually create Index/Skillset for full field control. Reference `03_multimodal_search.ipynb`.\n",
    "\n",
    "**Solution 3: Use Knowledge Store to Export Original Images**\n",
    "\n",
    "Configure Knowledge Store projection to Blob Storage in Skillset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf7956c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"image-alternatives\"></a>\n",
    "## üîß What If You Need Original Images or Location Information?\n",
    "\n",
    "### Solution 1: Trace Back via blob_url (Recommended)\n",
    "\n",
    "```python\n",
    "# Get source document URL from search results\n",
    "blob_url = search_result[\"blob_url\"]\n",
    "\n",
    "# Use Document Intelligence API to re-parse\n",
    "from azure.ai.documentintelligence import DocumentIntelligenceClient\n",
    "client = DocumentIntelligenceClient(endpoint=di_endpoint, credential=credential)\n",
    "result = client.begin_analyze_document(\"prebuilt-layout\", {\"urlSource\": blob_url}).result()\n",
    "```\n",
    "\n",
    "### Solution 2: Use Traditional Indexer + Custom Index Schema\n",
    "\n",
    "Manually create Index/Skillset for full field control\n",
    "\n",
    "### Solution 3: Use Knowledge Store to Export Original Images\n",
    "\n",
    "Configure Knowledge Store projection to Blob Storage in Skillset\n",
    "\n",
    "---\n",
    "\n",
    "### üìä Knowledge Source API vs Traditional Approach Comparison\n",
    "\n",
    "| Aspect | Knowledge Source API | Traditional Indexer + Skillset |\n",
    "|--------|---------------------|-------------------------------|\n",
    "| **Code Amount** | 1 line to create | Need to configure 4+ components |\n",
    "| **Index Schema** | Fixed 6 fields | Fully customizable |\n",
    "| **Location Metadata** | ‚ùå Not saved | ‚úÖ Configurable |\n",
    "| **Original Images** | ‚ùå Not saved | ‚úÖ Can export |\n",
    "| **Use Cases** | Rapid prototyping | Production systems |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
