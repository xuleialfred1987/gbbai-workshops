{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d27f0c7",
   "metadata": {},
   "source": [
    "# Azure Foundry IQ - Complete Knowledge Base Guide\n",
    "\n",
    "## üìã Overview\n",
    "\n",
    "**Foundry IQ** is the brand name for Azure AI Search's Agentic Retrieval capability, designed specifically for RAG (Retrieval Augmented Generation) and Agent grounding scenarios. It implements the separation of **domain knowledge** from **Agent logic**, allowing multiple Agents to share the same knowledge base.\n",
    "\n",
    "### üîë Core Concepts\n",
    "\n",
    "```mermaid\n",
    "flowchart TB\n",
    "    subgraph KB[\"Knowledge Base\"]\n",
    "        direction TB\n",
    "        LLM[\"ü§ñ LLM Connection Config\"]\n",
    "        RI[\"üìù Retrieval Instructions\"]\n",
    "        AI[\"üìù Answer Instructions\"]\n",
    "        OM[\"‚öôÔ∏è Output Mode / Reasoning Effort\"]\n",
    "    end\n",
    "\n",
    "    subgraph Sources[\"Knowledge Sources\"]\n",
    "        KS1[\"üìÇ Search Index\"]\n",
    "        KS2[\"üìÇ Azure Blob\"]\n",
    "        KS3[\"üìÇ SharePoint\"]\n",
    "        KS4[\"üìÇ OneLake\"]\n",
    "        KS5[\"üåê Web (Bing)\"]\n",
    "    end\n",
    "\n",
    "    subgraph Indexes[\"Search Indexes\"]\n",
    "        IDX1[(Index A)]\n",
    "        IDX2[(Index B)]\n",
    "    end\n",
    "\n",
    "    KB -->|\"references\"| Sources\n",
    "    KS1 --> IDX1\n",
    "    KS2 --> IDX2\n",
    "```\n",
    "\n",
    "### üìä Output Mode and Reasoning Effort\n",
    "\n",
    "| Output Mode | Description | Use Case |\n",
    "|-------------|-------------|----------|\n",
    "| `ANSWER_SYNTHESIS` | LLM generates natural language answers with citations | Direct user-facing Q&A |\n",
    "| `EXTRACTED_DATA` | Returns raw search results | Agent integration, letting Agent control response format |\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "| Reasoning Effort | Description | Latency | Cost |\n",
    "|------------------|-------------|---------|------|\n",
    "| `minimal` | Skips LLM query planning | ‚ö° Lowest | üí∞ Lowest |\n",
    "| `low` (default) | Single LLM query planning | Medium | Medium |\n",
    "| `medium` | Iterative query optimization | Higher | Higher |\n",
    "\n",
    "---\n",
    "\n",
    "## üìë Table of Contents\n",
    "\n",
    "| Step | Content | Description |\n",
    "|------|---------|-------------|\n",
    "| [Step 1](#step-1-configure-environment-variables) | Configure Environment Variables | Set up Azure AI Search and Azure OpenAI connections |\n",
    "| [Step 2](#step-2-create-search-index-with-agentic-retrieval-support) | Create Search Index | Configure vector search, semantic search, vectorizer |\n",
    "| [Step 3](#step-3-upload-sample-documents) | Upload Documents | Generate embeddings and index documents |\n",
    "| [Step 4](#step-4-create-knowledge-source) | Create Knowledge Source | Define data source reference and field mappings |\n",
    "| [Step 5](#step-5-create-knowledge-base) | Create Knowledge Base | Configure LLM, output mode, retrieval instructions |\n",
    "| [Step 6](#step-6-query-knowledge-base-agentic-retrieval) | Query Knowledge Base | Use Agentic Retrieval for Q&A |\n",
    "| [Step 7](#step-7-view-and-manage-resources) | Manage Resources | List created KB and KS |\n",
    "| [Step 8](#step-8-foundry-agent-service-integration-advanced) | Agent Integration | Foundry Agent Service integration example |\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Reference Documentation\n",
    "\n",
    "- [Agentic Retrieval Overview](https://learn.microsoft.com/en-us/azure/search/agentic-retrieval-overview)\n",
    "- [Create Knowledge Base](https://learn.microsoft.com/en-us/azure/search/agentic-retrieval-how-to-create-knowledge-base)\n",
    "- [Knowledge Source Types](https://learn.microsoft.com/en-us/azure/search/agentic-knowledge-source-overview)\n",
    "- [Foundry Agent Service Integration](https://learn.microsoft.com/en-us/azure/ai-foundry/agents/how-to/tools/knowledge-retrieval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be681128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (using latest preview version)\n",
    "%pip install azure-search-documents azure-identity python-dotenv openai requests --pre -qU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be28795",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.search.documents.indexes.models import (\n",
    "    SearchIndex,\n",
    "    SearchField,\n",
    "    VectorSearch,\n",
    "    VectorSearchProfile,\n",
    "    HnswAlgorithmConfiguration,\n",
    "    AzureOpenAIVectorizer,\n",
    "    AzureOpenAIVectorizerParameters,\n",
    "    SemanticSearch,\n",
    "    SemanticConfiguration,\n",
    "    SemanticPrioritizedFields,\n",
    "    SemanticField,\n",
    "    SearchIndexKnowledgeSource,\n",
    "    SearchIndexKnowledgeSourceParameters,\n",
    "    SearchIndexFieldReference,\n",
    "    KnowledgeBase,\n",
    "    KnowledgeBaseAzureOpenAIModel,\n",
    "    KnowledgeSourceReference,\n",
    "    KnowledgeRetrievalOutputMode,\n",
    "    KnowledgeRetrievalLowReasoningEffort,\n",
    "    KnowledgeRetrievalMinimalReasoningEffort,\n",
    "    KnowledgeRetrievalMediumReasoningEffort\n",
    ")\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "print(\"‚úÖ Packages imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139f47e7",
   "metadata": {},
   "source": [
    "## Step 1: Configure Environment Variables\n",
    "\n",
    "Set up Azure AI Search and Azure OpenAI connection information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4a3dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Configuration Parameters\n",
    "# ============================================\n",
    "\n",
    "# Azure AI Search Configuration\n",
    "search_endpoint = os.getenv(\"AZURE_SEARCH_ENDPOINT\")  # e.g., https://your-search.search.windows.net\n",
    "search_api_key = os.getenv(\"AZURE_SEARCH_API_KEY\")    # Admin key\n",
    "\n",
    "# Azure OpenAI Configuration\n",
    "aoai_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")    # e.g., https://your-openai.openai.azure.com\n",
    "aoai_api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "\n",
    "# Model deployment names (read from environment variables)\n",
    "embedding_deployment = os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT\", \"embedding\")\n",
    "embedding_model = os.getenv(\"AZURE_OPENAI_EMBEDDING_MODEL\", \"text-embedding-ada-002\")\n",
    "embedding_dimensions = 1536  # text-embedding-ada-002 dimensions\n",
    "\n",
    "gpt_deployment = os.getenv(\"AZURE_OPENAI_DEPLOYMENT\", \"gpt-4o-mini\")\n",
    "gpt_model = gpt_deployment\n",
    "\n",
    "# Resource naming\n",
    "index_name = \"foundry-iq-demo-index\"\n",
    "knowledge_source_name = \"foundry-iq-knowledge-source\"\n",
    "knowledge_base_name = \"foundry-iq-knowledge-base\"\n",
    "\n",
    "# Verify configuration\n",
    "print(\"üìã Configuration Check:\")\n",
    "print(f\"   Search Endpoint: {search_endpoint}\")\n",
    "print(f\"   OpenAI Endpoint: {aoai_endpoint}\")\n",
    "print(f\"   Embedding Model: {embedding_deployment}\")\n",
    "print(f\"   GPT Model: {gpt_deployment}\")\n",
    "print(f\"   Index Name: {index_name}\")\n",
    "print(f\"   Knowledge Source: {knowledge_source_name}\")\n",
    "print(f\"   Knowledge Base: {knowledge_base_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e0d2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize clients\n",
    "# Choose authentication method: API Key or RBAC\n",
    "\n",
    "# Method 1: Using API Key (simple but not recommended for production)\n",
    "credential = AzureKeyCredential(search_api_key)\n",
    "\n",
    "# Method 2: Using RBAC (recommended for production)\n",
    "# credential = DefaultAzureCredential()\n",
    "\n",
    "# Create index client\n",
    "index_client = SearchIndexClient(\n",
    "    endpoint=search_endpoint,\n",
    "    credential=credential\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Client initialized successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265afb08",
   "metadata": {},
   "source": [
    "## Step 2: Create Search Index with Agentic Retrieval Support\n",
    "\n",
    "The index needs to include:\n",
    "- Text fields (for keyword search and semantic ranking)\n",
    "- Vector fields (for vector search)\n",
    "- Vectorizer (for automatic query vectorization)\n",
    "- Semantic configuration (for semantic reranking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22be4a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create index definition\n",
    "index = SearchIndex(\n",
    "    name=index_name,\n",
    "    fields=[\n",
    "        # Primary key\n",
    "        SearchField(\n",
    "            name=\"id\",\n",
    "            type=\"Edm.String\",\n",
    "            key=True,\n",
    "            filterable=True,\n",
    "            sortable=True\n",
    "        ),\n",
    "        # Document title\n",
    "        SearchField(\n",
    "            name=\"title\",\n",
    "            type=\"Edm.String\",\n",
    "            searchable=True,\n",
    "            filterable=True,\n",
    "            sortable=True\n",
    "        ),\n",
    "        # Document content (for search and semantic ranking)\n",
    "        SearchField(\n",
    "            name=\"content\",\n",
    "            type=\"Edm.String\",\n",
    "            searchable=True,\n",
    "            filterable=False,\n",
    "            sortable=False\n",
    "        ),\n",
    "        # Vector field\n",
    "        SearchField(\n",
    "            name=\"content_vector\",\n",
    "            type=\"Collection(Edm.Single)\",\n",
    "            stored=False,  # Don't store to save space\n",
    "            vector_search_dimensions=embedding_dimensions,\n",
    "            vector_search_profile_name=\"vector_profile\"\n",
    "        ),\n",
    "        # Metadata fields\n",
    "        SearchField(\n",
    "            name=\"source\",\n",
    "            type=\"Edm.String\",\n",
    "            filterable=True,\n",
    "            facetable=True\n",
    "        ),\n",
    "        SearchField(\n",
    "            name=\"page_number\",\n",
    "            type=\"Edm.Int32\",\n",
    "            filterable=True,\n",
    "            sortable=True\n",
    "        ),\n",
    "        SearchField(\n",
    "            name=\"category\",\n",
    "            type=\"Edm.String\",\n",
    "            filterable=True,\n",
    "            facetable=True\n",
    "        )\n",
    "    ],\n",
    "    # Vector search configuration\n",
    "    vector_search=VectorSearch(\n",
    "        profiles=[\n",
    "            VectorSearchProfile(\n",
    "                name=\"vector_profile\",\n",
    "                algorithm_configuration_name=\"hnsw_config\",\n",
    "                vectorizer_name=\"azure_openai_vectorizer\"  # Auto-vectorize at query time\n",
    "            )\n",
    "        ],\n",
    "        algorithms=[\n",
    "            HnswAlgorithmConfiguration(\n",
    "                name=\"hnsw_config\",\n",
    "                # Optional parameters: m=4, ef_construction=400, ef_search=500\n",
    "            )\n",
    "        ],\n",
    "        vectorizers=[\n",
    "            AzureOpenAIVectorizer(\n",
    "                vectorizer_name=\"azure_openai_vectorizer\",\n",
    "                parameters=AzureOpenAIVectorizerParameters(\n",
    "                    resource_url=aoai_endpoint,\n",
    "                    deployment_name=embedding_deployment,\n",
    "                    model_name=embedding_model,\n",
    "                    api_key=aoai_api_key\n",
    "                )\n",
    "            )\n",
    "        ]\n",
    "    ),\n",
    "    # Semantic search configuration (must enable semantic ranking)\n",
    "    semantic_search=SemanticSearch(\n",
    "        default_configuration_name=\"semantic_config\",\n",
    "        configurations=[\n",
    "            SemanticConfiguration(\n",
    "                name=\"semantic_config\",\n",
    "                prioritized_fields=SemanticPrioritizedFields(\n",
    "                    title_field=SemanticField(field_name=\"title\"),\n",
    "                    content_fields=[SemanticField(field_name=\"content\")]\n",
    "                )\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "# Create or update index\n",
    "index_client.create_or_update_index(index)\n",
    "print(f\"‚úÖ Index '{index_name}' created successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5259ff60",
   "metadata": {},
   "source": [
    "## Step 3: Upload Sample Documents\n",
    "\n",
    "Upload some sample documents to the index. In real scenarios, you can:\n",
    "- Extract text from PDF, Word, and other documents\n",
    "- Use Azure Document Intelligence to process complex documents\n",
    "- Use Indexer to automatically pull data from Blob, SharePoint, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b67d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "\n",
    "# Initialize Azure OpenAI client for generating embeddings\n",
    "aoai_client = AzureOpenAI(\n",
    "    api_key=aoai_api_key,\n",
    "    api_version=\"2024-06-01\",\n",
    "    azure_endpoint=aoai_endpoint\n",
    ")\n",
    "\n",
    "def generate_embedding(text: str) -> list[float]:\n",
    "    \"\"\"Generate vector embedding for text\"\"\"\n",
    "    response = aoai_client.embeddings.create(\n",
    "        input=text,\n",
    "        model=embedding_deployment\n",
    "    )\n",
    "    return response.data[0].embedding\n",
    "\n",
    "# Sample documents (about Azure AI services)\n",
    "sample_documents = [\n",
    "    {\n",
    "        \"id\": \"doc1\",\n",
    "        \"title\": \"Azure AI Search Overview\",\n",
    "        \"content\": \"Azure AI Search is an enterprise-grade search service that provides vector search, full-text search, and semantic search capabilities. It supports Agentic Retrieval and can integrate with LLMs for intelligent retrieval. Key features include: vector search supporting multiple algorithms (HNSW, exhaustive KNN), semantic reranking for improved search relevance, and hybrid search combining keyword and vector search advantages.\",\n",
    "        \"source\": \"azure-docs\",\n",
    "        \"page_number\": 1,\n",
    "        \"category\": \"search\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"doc2\",\n",
    "        \"title\": \"Foundry IQ Introduction\",\n",
    "        \"content\": \"Foundry IQ is the brand name for Azure AI Search's Agentic Retrieval capability. It creates a separation between domain knowledge and Agent logic, supporting large-scale RAG and grounding. Through the concepts of Knowledge Base and Knowledge Source, you can independently manage knowledge content, and multiple Agents can share the same knowledge base.\",\n",
    "        \"source\": \"azure-docs\",\n",
    "        \"page_number\": 2,\n",
    "        \"category\": \"ai\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"doc3\",\n",
    "        \"title\": \"Knowledge Base Configuration\",\n",
    "        \"content\": \"Knowledge Base is the core of the Agentic Retrieval pipeline. It defines which knowledge sources to query and the default behavior of retrieval operations. Key properties include: name (unique identifier), description (used by LLM for query planning), knowledge_sources (one or more knowledge source references), models (LLM connection info), output_mode (answer_synthesis or extracted_data), retrieval_reasoning_effort (minimal, low, medium).\",\n",
    "        \"source\": \"azure-docs\",\n",
    "        \"page_number\": 3,\n",
    "        \"category\": \"configuration\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"doc4\",\n",
    "        \"title\": \"Knowledge Source Types\",\n",
    "        \"content\": \"Azure AI Search supports multiple types of Knowledge Sources: 1) searchIndex - wraps existing indexes, 2) azureBlob - generates indexer pipeline pulling from Blob containers, 3) indexedOneLake - pulls from OneLake, 4) indexedSharePoint - pulls from SharePoint sites, 5) remoteSharePoint - directly queries SharePoint, 6) webParameters - gets real-time grounding data from Bing.\",\n",
    "        \"source\": \"azure-docs\",\n",
    "        \"page_number\": 4,\n",
    "        \"category\": \"configuration\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"doc5\",\n",
    "        \"title\": \"Retrieval Reasoning Effort\",\n",
    "        \"content\": \"Retrieval Reasoning Effort determines the level of LLM-related query processing. minimal - bypasses LLM query planning, reducing cost and latency; low (default) - balanced LLM processing approach; medium - maximizes LLM processing for improved relevance. For Foundry Agent Service integration, minimal is recommended for better performance and lower cost.\",\n",
    "        \"source\": \"azure-docs\",\n",
    "        \"page_number\": 5,\n",
    "        \"category\": \"performance\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"doc6\",\n",
    "        \"title\": \"MCP Tool Integration\",\n",
    "        \"content\": \"Model Context Protocol (MCP) is the standard protocol for Agent to Knowledge Base communication. In Foundry Agent Service, you can create a RemoteTool connection using the project's managed identity to connect to the Knowledge Base's MCP endpoint. The Agent calls the knowledge_base_retrieve MCP tool at runtime to retrieve relevant content and generate responses with citations.\",\n",
    "        \"source\": \"azure-docs\",\n",
    "        \"page_number\": 6,\n",
    "        \"category\": \"integration\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Generate vector embeddings for each document\n",
    "print(\"üîÑ Generating vector embeddings...\")\n",
    "for doc in sample_documents:\n",
    "    doc[\"content_vector\"] = generate_embedding(doc[\"content\"])\n",
    "    print(f\"   ‚úì {doc['title']}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Embeddings generated for all {len(sample_documents)} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04d1b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload documents to index\n",
    "search_client = SearchClient(\n",
    "    endpoint=search_endpoint,\n",
    "    index_name=index_name,\n",
    "    credential=credential\n",
    ")\n",
    "\n",
    "result = search_client.upload_documents(documents=sample_documents)\n",
    "succeeded = sum(1 for r in result if r.succeeded)\n",
    "print(f\"‚úÖ Successfully uploaded {succeeded}/{len(sample_documents)} documents to index '{index_name}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2376f1",
   "metadata": {},
   "source": [
    "## Step 4: Create Knowledge Source\n",
    "\n",
    "Knowledge Source is a reusable reference to source data. It specifies:\n",
    "- Target index\n",
    "- Which fields to include in references\n",
    "- Optional description (helps LLM with knowledge source selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437d976d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Knowledge Source\n",
    "knowledge_source = SearchIndexKnowledgeSource(\n",
    "    name=knowledge_source_name,\n",
    "    description=\"Knowledge source for Azure AI service documentation, including Azure AI Search, Foundry IQ, Knowledge Base configuration, etc.\",\n",
    "    search_index_parameters=SearchIndexKnowledgeSourceParameters(\n",
    "        search_index_name=index_name,\n",
    "        # Specify fields to include in references (avoid large fields like vectors)\n",
    "        source_data_fields=[\n",
    "            SearchIndexFieldReference(name=\"id\"),\n",
    "            SearchIndexFieldReference(name=\"title\"),\n",
    "            SearchIndexFieldReference(name=\"source\"),\n",
    "            SearchIndexFieldReference(name=\"page_number\"),\n",
    "            SearchIndexFieldReference(name=\"category\")\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "# Create or update Knowledge Source\n",
    "index_client.create_or_update_knowledge_source(knowledge_source=knowledge_source)\n",
    "print(f\"‚úÖ Knowledge Source '{knowledge_source_name}' created successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11f5649",
   "metadata": {},
   "source": [
    "## Step 5: Create Knowledge Base\n",
    "\n",
    "Knowledge Base is the core of the Agentic Retrieval pipeline. It:\n",
    "- Connects one or more Knowledge Sources\n",
    "- Configures LLM for query planning and answer synthesis\n",
    "- Defines output mode and retrieval behavior\n",
    "\n",
    "### Output Mode Options\n",
    "- `ANSWER_SYNTHESIS`: LLM generates natural language answers with citations\n",
    "- `EXTRACTED_DATA`: Returns raw search results for downstream Agent processing\n",
    "\n",
    "### Reasoning Effort Options\n",
    "- `minimal`: Skips LLM query planning, lowest latency and cost\n",
    "- `low` (default): Balanced LLM processing\n",
    "- `medium`: Maximizes LLM processing for improved relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f1b8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Azure OpenAI connection parameters\n",
    "aoai_params = AzureOpenAIVectorizerParameters(\n",
    "    resource_url=aoai_endpoint,\n",
    "    deployment_name=gpt_deployment,\n",
    "    model_name=gpt_model,\n",
    "    api_key=aoai_api_key\n",
    ")\n",
    "\n",
    "# Create Knowledge Base\n",
    "knowledge_base = KnowledgeBase(\n",
    "    name=knowledge_base_name,\n",
    "    description=\"Azure AI services knowledge base for answering questions about Azure AI Search, Foundry IQ, and Agentic Retrieval\",\n",
    "    \n",
    "    # Retrieval instructions: Guide LLM on how to select knowledge sources and formulate queries\n",
    "    retrieval_instructions=\"Use this knowledge source to answer questions about Azure AI services. If the question involves search, knowledge bases, or Agent integration, use this knowledge source.\",\n",
    "    \n",
    "    # Answer instructions: Guide LLM on how to format answers\n",
    "    answer_instructions=\"Provide clear, accurate answers based on retrieved documents. Cite source document titles and page numbers when relevant.\",\n",
    "    \n",
    "    # Output mode\n",
    "    output_mode=KnowledgeRetrievalOutputMode.ANSWER_SYNTHESIS,\n",
    "    \n",
    "    # Knowledge source list\n",
    "    knowledge_sources=[\n",
    "        KnowledgeSourceReference(name=knowledge_source_name)\n",
    "    ],\n",
    "    \n",
    "    # LLM model configuration\n",
    "    models=[KnowledgeBaseAzureOpenAIModel(azure_open_ai_parameters=aoai_params)],\n",
    "    \n",
    "    # Retrieval reasoning effort level\n",
    "    # Use minimal for lower latency and cost (recommended for Foundry Agent Service integration)\n",
    "    # Use low or medium for better query planning and relevance\n",
    "    retrieval_reasoning_effort=KnowledgeRetrievalLowReasoningEffort\n",
    ")\n",
    "\n",
    "# Create or update Knowledge Base\n",
    "index_client.create_or_update_knowledge_base(knowledge_base)\n",
    "print(f\"‚úÖ Knowledge Base '{knowledge_base_name}' created successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d82819",
   "metadata": {},
   "source": [
    "## Step 6: Query Knowledge Base (Agentic Retrieval)\n",
    "\n",
    "Use `KnowledgeBaseRetrievalClient` to send query requests to the knowledge base.\n",
    "\n",
    "Queries support:\n",
    "- Multi-turn conversations (via messages array)\n",
    "- Custom knowledge source parameters\n",
    "- Activity logs (for debugging and auditing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9cc418",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents.knowledgebases import KnowledgeBaseRetrievalClient\n",
    "from azure.search.documents.knowledgebases.models import (\n",
    "    KnowledgeBaseRetrievalRequest,\n",
    "    KnowledgeBaseMessage,\n",
    "    KnowledgeBaseMessageTextContent,\n",
    "    SearchIndexKnowledgeSourceParams\n",
    ")\n",
    "\n",
    "# Initialize retrieval client\n",
    "kb_client = KnowledgeBaseRetrievalClient(\n",
    "    endpoint=search_endpoint,\n",
    "    knowledge_base_name=knowledge_base_name,\n",
    "    credential=credential\n",
    ")\n",
    "\n",
    "def query_knowledge_base(question: str, conversation_history: list = None):\n",
    "    \"\"\"\n",
    "    Send a query to the Knowledge Base and return results\n",
    "    \n",
    "    Args:\n",
    "        question: User question\n",
    "        conversation_history: Optional conversation history\n",
    "    \n",
    "    Returns:\n",
    "        Retrieval results including answer and citations\n",
    "    \"\"\"\n",
    "    # Build message list\n",
    "    messages = []\n",
    "    \n",
    "    # Add conversation history (if any)\n",
    "    if conversation_history:\n",
    "        for msg in conversation_history:\n",
    "            messages.append(\n",
    "                KnowledgeBaseMessage(\n",
    "                    role=msg[\"role\"],\n",
    "                    content=[KnowledgeBaseMessageTextContent(text=msg[\"content\"])]\n",
    "                )\n",
    "            )\n",
    "    \n",
    "    # Add current question\n",
    "    messages.append(\n",
    "        KnowledgeBaseMessage(\n",
    "            role=\"user\",\n",
    "            content=[KnowledgeBaseMessageTextContent(text=question)]\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Build retrieval request\n",
    "    request = KnowledgeBaseRetrievalRequest(\n",
    "        messages=messages,\n",
    "        knowledge_source_params=[\n",
    "            SearchIndexKnowledgeSourceParams(\n",
    "                knowledge_source_name=knowledge_source_name,\n",
    "                include_references=True,           # Include reference information\n",
    "                include_reference_source_data=True, # Include source data details\n",
    "                always_query_source=True           # Always query this knowledge source\n",
    "            )\n",
    "        ],\n",
    "        include_activity=True  # Include activity logs (for debugging)\n",
    "    )\n",
    "    \n",
    "    # Execute retrieval\n",
    "    result = kb_client.retrieve(retrieval_request=request)\n",
    "    \n",
    "    return result\n",
    "\n",
    "print(\"‚úÖ Query function ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8b1b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test query 1: Basic question\n",
    "question = \"What is Foundry IQ? What are its advantages?\"\n",
    "\n",
    "print(f\"‚ùì Question: {question}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "result = query_knowledge_base(question)\n",
    "\n",
    "# Display answer\n",
    "if result.response:\n",
    "    for resp in result.response:\n",
    "        for content in resp.content:\n",
    "            print(f\"\\nüìù Answer:\\n{content.text}\")\n",
    "\n",
    "# Display citations\n",
    "if result.references:\n",
    "    print(f\"\\nüìö References ({len(result.references)}):\")\n",
    "    for i, ref in enumerate(result.references[:5], 1):\n",
    "        ref_dict = ref.as_dict()\n",
    "        source_data = ref_dict.get(\"sourceData\", {})\n",
    "        print(f\"   {i}. {source_data.get('title', 'N/A')} (Page {source_data.get('page_number', 'N/A')})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b009eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test query 2: Technical details\n",
    "question = \"What Retrieval Reasoning Effort levels does Knowledge Base support? What are their characteristics?\"\n",
    "\n",
    "print(f\"‚ùì Question: {question}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "result = query_knowledge_base(question)\n",
    "\n",
    "# Display answer\n",
    "if result.response:\n",
    "    for resp in result.response:\n",
    "        for content in resp.content:\n",
    "            print(f\"\\nüìù Answer:\\n{content.text}\")\n",
    "\n",
    "# Display citations\n",
    "if result.references:\n",
    "    print(f\"\\nüìö References ({len(result.references)}):\")\n",
    "    for i, ref in enumerate(result.references[:5], 1):\n",
    "        ref_dict = ref.as_dict()\n",
    "        source_data = ref_dict.get(\"sourceData\", {})\n",
    "        print(f\"   {i}. {source_data.get('title', 'N/A')} (Page {source_data.get('page_number', 'N/A')})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc4e759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test query 3: Multi-turn conversation\n",
    "conversation = [\n",
    "    {\"role\": \"user\", \"content\": \"What are the main features of Azure AI Search?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Azure AI Search provides vector search, full-text search, and semantic search capabilities, supporting Agentic Retrieval.\"}\n",
    "]\n",
    "\n",
    "follow_up = \"How does it integrate with LLMs?\"\n",
    "\n",
    "print(f\"üí¨ Conversation history: {len(conversation)} turns\")\n",
    "print(f\"‚ùì Follow-up: {follow_up}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "result = query_knowledge_base(follow_up, conversation)\n",
    "\n",
    "# Display answer\n",
    "if result.response:\n",
    "    for resp in result.response:\n",
    "        for content in resp.content:\n",
    "            print(f\"\\nüìù Answer:\\n{content.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d827860",
   "metadata": {},
   "source": [
    "## Step 7: View and Manage Resources\n",
    "\n",
    "List the created Knowledge Bases and Knowledge Sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc5a303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all Knowledge Bases\n",
    "print(\"üìã Created Knowledge Bases:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Use REST API to list Knowledge Bases\n",
    "kb_list_url = f\"{search_endpoint}/knowledgebases\"\n",
    "params = {\"api-version\": \"2025-11-01-preview\", \"$select\": \"name,description\"}\n",
    "headers = {\"api-key\": search_api_key}\n",
    "\n",
    "response = requests.get(kb_list_url, params=params, headers=headers)\n",
    "if response.status_code == 200:\n",
    "    kbs = response.json().get(\"value\", [])\n",
    "    for kb in kbs:\n",
    "        print(f\"   ‚Ä¢ {kb.get('name')}: {kb.get('description', 'No description')}\")\n",
    "else:\n",
    "    print(f\"   ‚ö†Ô∏è Unable to get list: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b755f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all Knowledge Sources\n",
    "print(\"üìã Created Knowledge Sources:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "ks_list_url = f\"{search_endpoint}/knowledgesources\"\n",
    "params = {\"api-version\": \"2025-11-01-preview\", \"$select\": \"name,description\"}\n",
    "\n",
    "response = requests.get(ks_list_url, params=params, headers=headers)\n",
    "if response.status_code == 200:\n",
    "    sources = response.json().get(\"value\", [])\n",
    "    for ks in sources:\n",
    "        print(f\"   ‚Ä¢ {ks.get('name')}: {ks.get('description', 'No description')}\")\n",
    "else:\n",
    "    print(f\"   ‚ö†Ô∏è Unable to get list: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f284c8",
   "metadata": {},
   "source": [
    "## Step 8: Foundry Agent Service Integration (Advanced)\n",
    "\n",
    "The following code demonstrates how to integrate Knowledge Base with Microsoft Foundry Agent Service.\n",
    "\n",
    "### Prerequisites\n",
    "- Microsoft Foundry project\n",
    "- Project managed identity configuration\n",
    "- Proper RBAC role assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb14f4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Foundry Agent Service integration example (requires additional configuration)\n",
    "\n",
    "# Note: The following code requires a configured Microsoft Foundry project\n",
    "# and the azure-ai-projects package installed\n",
    "\n",
    "# %pip install azure-ai-projects --pre -qU\n",
    "\n",
    "FOUNDRY_INTEGRATION_EXAMPLE = \"\"\"\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "# Configuration\n",
    "project_endpoint = \"https://your-project.services.ai.azure.com/api/projects/your-project-name\"\n",
    "knowledge_base_mcp_endpoint = f\"{search_endpoint}/knowledgebases/{knowledge_base_name}/mcp\"\n",
    "\n",
    "# Initialize project client\n",
    "credential = DefaultAzureCredential()\n",
    "project_client = AIProjectClient(endpoint=project_endpoint, credential=credential)\n",
    "\n",
    "# Create project connection (for MCP communication)\n",
    "# This needs to be created via Azure Management API as a RemoteTool connection\n",
    "\n",
    "# Create Agent with MCP tools\n",
    "agent = project_client.agents.create_agent(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    name=\"knowledge-retrieval-agent\",\n",
    "    instructions='''You are a helpful assistant that must use the knowledge base to answer all questions.\n",
    "Every answer must provide annotations using the MCP knowledge base tool.\n",
    "If you cannot find the answer, respond with \"I don't know\".''',\n",
    "    tools=[{\n",
    "        \"type\": \"mcp\",\n",
    "        \"mcp\": {\n",
    "            \"server_label\": \"AzureAISearch\",\n",
    "            \"allowed_tools\": [\"knowledge_base_retrieve\"]\n",
    "        }\n",
    "    }],\n",
    "    tool_resources={\n",
    "        \"mcp\": {\n",
    "            \"connections\": {\n",
    "                \"AzureAISearch\": {\n",
    "                    \"connection_string\": \"your-project-connection-name\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"Agent created: {agent.name}\")\n",
    "\"\"\"\n",
    "\n",
    "print(\"üìò Foundry Agent Service integration example code:\")\n",
    "print(FOUNDRY_INTEGRATION_EXAMPLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9539869",
   "metadata": {},
   "source": [
    "## Clean Up Resources (Optional)\n",
    "\n",
    "‚ö†Ô∏è **Warning**: Running the following code will delete all created resources!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb788909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚ö†Ô∏è Dangerous Operation - Delete Resources ‚ö†Ô∏è\n",
    "# Uncomment the following code to execute deletion\n",
    "\n",
    "# confirm = input(\"Enter 'DELETE' to confirm deletion of all resources: \")\n",
    "# if confirm == \"DELETE\":\n",
    "#     # 1. Delete Knowledge Base (must delete first as it references Knowledge Source)\n",
    "#     try:\n",
    "#         index_client.delete_knowledge_base(knowledge_base_name)\n",
    "#         print(f\"‚úÖ Knowledge Base '{knowledge_base_name}' deleted\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"‚ö†Ô∏è Failed to delete Knowledge Base: {e}\")\n",
    "#     \n",
    "#     # 2. Delete Knowledge Source\n",
    "#     try:\n",
    "#         index_client.delete_knowledge_source(knowledge_source=knowledge_source_name)\n",
    "#         print(f\"‚úÖ Knowledge Source '{knowledge_source_name}' deleted\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"‚ö†Ô∏è Failed to delete Knowledge Source: {e}\")\n",
    "#     \n",
    "#     # 3. Delete index (optional, don't delete if index is used for other purposes)\n",
    "#     try:\n",
    "#         index_client.delete_index(index_name)\n",
    "#         print(f\"‚úÖ Index '{index_name}' deleted\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"‚ö†Ô∏è Failed to delete Index: {e}\")\n",
    "#     \n",
    "#     print(\"\\n‚úÖ All resources cleaned up!\")\n",
    "# else:\n",
    "#     print(\"Deletion cancelled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3f643a",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated the complete Azure Foundry IQ workflow:\n",
    "\n",
    "1. **Create Search Index** - Configure vector search, semantic search, and vectorizer\n",
    "2. **Upload Documents** - Generate embeddings and index documents\n",
    "3. **Create Knowledge Source** - Define data source reference\n",
    "4. **Create Knowledge Base** - Configure retrieval pipeline and LLM connection\n",
    "5. **Query Knowledge Base** - Use Agentic Retrieval for Q&A\n",
    "\n",
    "## Related Resources\n",
    "\n",
    "- [Agentic Retrieval Overview](https://learn.microsoft.com/en-us/azure/search/agentic-retrieval-overview)\n",
    "- [Create Knowledge Base](https://learn.microsoft.com/en-us/azure/search/agentic-retrieval-how-to-create-knowledge-base)\n",
    "- [Knowledge Source Types](https://learn.microsoft.com/en-us/azure/search/agentic-knowledge-source-overview)\n",
    "- [Foundry Agent Service Integration](https://learn.microsoft.com/en-us/azure/ai-foundry/agents/how-to/tools/knowledge-retrieval)\n",
    "- [GitHub Sample Code](https://github.com/Azure-Samples/azure-search-python-samples/tree/main/agentic-retrieval-pipeline-example)\n",
    "\n",
    "## Best Practices\n",
    "\n",
    "1. **Choose the right Reasoning Effort**:\n",
    "   - Use `minimal` when integrating with Foundry Agent Service\n",
    "   - Use `low` or `medium` when complex query planning is needed\n",
    "\n",
    "2. **Choose the right Output Mode**:\n",
    "   - `extracted_data`: Let Agent control response format (recommended for Agent integration)\n",
    "   - `answer_synthesis`: Get formatted answers directly\n",
    "\n",
    "3. **Security**:\n",
    "   - Use RBAC instead of API Key in production\n",
    "   - Configure managed identity for service-to-service authentication\n",
    "\n",
    "4. **Performance Optimization**:\n",
    "   - Use vectorizer for automatic query vectorization\n",
    "   - Set `source_data_fields` appropriately to avoid returning large fields"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
